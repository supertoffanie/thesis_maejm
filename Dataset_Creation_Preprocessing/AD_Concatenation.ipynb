{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5545a9a4-099a-4662-9b31-4b9a4ab722e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "BENCHMARK 4: CONCATENATION FUSION (vs Tensor Fusion)\n",
      "================================================================================\n",
      "\n",
      "Device: cuda\n",
      "\n",
      "Loading valid patient list...\n",
      "Valid patients: 161\n",
      "  Processed: 161 valid patients\n",
      "  Skipped (not in valid set): 221\n",
      "Total sequences: 161\n",
      "\n",
      "Training...\n",
      "Epoch 1/100 - Loss: 130.8061, C-index: 0.4272\n",
      "Epoch 2/100 - Loss: 126.9472, C-index: 0.6052\n",
      "Epoch 3/100 - Loss: 112.3578, C-index: 0.7443\n",
      "Epoch 4/100 - Loss: 88.8343, C-index: 0.5890\n",
      "Epoch 5/100 - Loss: 61.7459, C-index: 0.2104\n",
      "Epoch 6/100 - Loss: 35.4176, C-index: 0.2006\n",
      "Epoch 7/100 - Loss: 15.2519, C-index: 0.2201\n",
      "Epoch 8/100 - Loss: 5.8667, C-index: 0.2395\n",
      "Epoch 9/100 - Loss: 7.3109, C-index: 0.2427\n",
      "Epoch 10/100 - Loss: 6.0735, C-index: 0.2751\n",
      "Epoch 11/100 - Loss: 5.5766, C-index: 0.3010\n",
      "Epoch 12/100 - Loss: 5.4346, C-index: 0.2783\n",
      "Epoch 13/100 - Loss: 5.0478, C-index: 0.2071\n",
      "Epoch 14/100 - Loss: 3.9996, C-index: 0.1748\n",
      "Epoch 15/100 - Loss: 3.6109, C-index: 0.1748\n",
      "Epoch 16/100 - Loss: 3.1099, C-index: 0.1812\n",
      "Epoch 17/100 - Loss: 3.4874, C-index: 0.1812\n",
      "Epoch 18/100 - Loss: 2.8123, C-index: 0.2492\n",
      "\n",
      "✓ Exported to concat_fusion_features.csv\n",
      "  Patients: 161\n",
      "  Visits: 948\n",
      "  Features: 128\n",
      "\n",
      "================================================================================\n",
      "✓ BEST C-INDEX: 0.7443\n",
      "⚠️  This uses the SAME patient cohort as all other benchmarks\n",
      "================================================================================\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Benchmark 4: Concatenation Fusion\n",
    "Simple concatenation instead of tensor fusion\n",
    "\n",
    "FIXED VERSION:\n",
    "- Uses VALID_PATIENTS.pkl for consistent patient cohort\n",
    "- Survival time measured from MCI diagnosis (consistent)\n",
    "- Proper feature standardization and NaN handling\n",
    "- Shows that tensor fusion is superior to naive concatenation\n",
    "\n",
    "Architecture:\n",
    "- Same as thesis BUT: simple concatenation [img; tab] instead of tensor product\n",
    "- Everything else identical (LSTM, autoencoder, etc.)\n",
    "- Expected to be worse than thesis but better than single modality\n",
    "\"\"\"\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torchvision import models, transforms\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from PIL import Image\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import pickle\n",
    "from lifelines.utils import concordance_index\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "CONFIG = {\n",
    "    'latent_dim': 128,\n",
    "    'img_out_dim': 256,\n",
    "    'tab_out_dim': 64,\n",
    "    'lstm_hidden': 128,\n",
    "    'lstm_layers': 2,\n",
    "    'dropout': 0.3,\n",
    "    'lr': 5e-4,\n",
    "    'weight_decay': 1e-4,\n",
    "    'epochs': 100,\n",
    "    'batch_size': 16,\n",
    "    'max_seq_len': 10,\n",
    "    'alpha_recon': 0.2,\n",
    "    'alpha_survival': 0.6,\n",
    "    'alpha_mmse': 0.2,\n",
    "    'device': 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "}\n",
    "\n",
    "# ============================================================================\n",
    "# FEATURE ENGINEERING (Same as thesis)\n",
    "# ============================================================================\n",
    "\n",
    "STATIC_FEATURES = [\n",
    "    'age_bl', 'PTGENDER_encoded', 'PTEDUCAT', 'PTETHCAT_encoded', \n",
    "    'PTRACCAT_encoded', 'PTMARRY_encoded'\n",
    "]\n",
    "\n",
    "TEMPORAL_FEATURES = [\n",
    "    'time_from_baseline', 'AGE', 'age_since_bl', 'mmse_slope', \n",
    "    'adas13_slope', 'dx_progression', 'cog_decline_index', \n",
    "    'visit_number', 'MMSE', 'ADAS13'\n",
    "]\n",
    "\n",
    "def engineer_features(df):\n",
    "    df = df.copy()\n",
    "    df[\"time_from_baseline\"] = df[\"Years_bl\"] - df[\"Years_bl\"].iloc[0]\n",
    "    df[\"age_bl\"] = df[\"AGE\"].iloc[0]\n",
    "    df[\"age_since_bl\"] = df[\"AGE\"] - df[\"age_bl\"]\n",
    "    df[\"mmse_slope\"] = df[\"MMSE\"].diff() / df[\"Years_bl\"].diff()\n",
    "    df[\"adas13_slope\"] = df[\"ADAS13\"].diff() / df[\"Years_bl\"].diff()\n",
    "    dx_map = {\"CN\": 0, \"MCI\": 1, \"AD\": 2, \"Dementia\": 2}\n",
    "    df[\"dx_progression\"] = df[\"DX\"].map(dx_map).diff()\n",
    "    df[\"cog_decline_index\"] = df[\"ADAS13\"] - df[\"MMSE\"]\n",
    "    df[\"visit_number\"] = range(len(df))\n",
    "    df['age_mmse_interaction'] = df['AGE'] * (30 - df['MMSE']) / 30\n",
    "    df['education_cognitive_reserve'] = df['PTEDUCAT'] * df['MMSE'] / 30\n",
    "    df['rapid_decline_flag'] = (df['mmse_slope'] < -2).astype(float)\n",
    "    mmse_bins = [0, 20, 24, 30]\n",
    "    df['mmse_severity'] = pd.cut(df['MMSE'], bins=mmse_bins, labels=[2, 1, 0]).astype(float)\n",
    "    df['weighted_mmse_decline'] = df['mmse_slope'] * np.exp(-0.1 * df['time_from_baseline'])\n",
    "    df['mmse_variability'] = df['MMSE'].rolling(window=3, min_periods=1).std()\n",
    "    df['adas_mmse_discordance'] = np.abs(\n",
    "        (df['ADAS13'] - df['ADAS13'].mean()) / (df['ADAS13'].std() + 1e-7) - \n",
    "        (df['MMSE'] - df['MMSE'].mean()) / (df['MMSE'].std() + 1e-7)\n",
    "    )\n",
    "    df = df.fillna(0)\n",
    "    return df\n",
    "\n",
    "TEMPORAL_FEATURES.extend([\n",
    "    'age_mmse_interaction', 'education_cognitive_reserve', 'rapid_decline_flag',\n",
    "    'mmse_severity', 'weighted_mmse_decline', 'mmse_variability', 'adas_mmse_discordance'\n",
    "])\n",
    "\n",
    "# ============================================================================\n",
    "# DATASET\n",
    "# ============================================================================\n",
    "\n",
    "class SequenceDataset(Dataset):\n",
    "    def __init__(self, manifest, valid_patients, transform=None, max_seq_len=10):\n",
    "        self.sequences = []\n",
    "        self.transform = transform\n",
    "        self.max_seq_len = max_seq_len\n",
    "        \n",
    "        manifest[\"path\"] = manifest[\"path\"].str.replace(\"\\\\\", \"/\", regex=False)\n",
    "        manifest[\"path\"] = \"./AD_Multimodal/TFN_AD/\" + manifest[\"path\"]\n",
    "        \n",
    "        processed = 0\n",
    "        skipped_not_valid = 0\n",
    "        \n",
    "        for ptid in manifest['PTID'].unique():\n",
    "            # CRITICAL: Only process valid patients\n",
    "            if ptid not in valid_patients:\n",
    "                skipped_not_valid += 1\n",
    "                continue\n",
    "            \n",
    "            try:\n",
    "                patient_rows = manifest[manifest['PTID'] == ptid]\n",
    "                if len(patient_rows) == 0:\n",
    "                    continue\n",
    "                \n",
    "                df = pd.read_pickle(patient_rows.iloc[0][\"path\"])\n",
    "                df = engineer_features(df)\n",
    "                \n",
    "                dx_seq = df[\"DX\"].tolist()\n",
    "                if \"MCI\" not in dx_seq:\n",
    "                    continue\n",
    "                \n",
    "                # FIXED: Time from MCI diagnosis\n",
    "                mci_idx = dx_seq.index(\"MCI\")\n",
    "                ad_idx = next((i for i, x in enumerate(dx_seq[mci_idx+1:], start=mci_idx+1) \n",
    "                              if x in [\"AD\", \"Dementia\"]), -1)\n",
    "                \n",
    "                if ad_idx != -1:\n",
    "                    time_to_event = df[\"Years_bl\"].iloc[ad_idx] - df[\"Years_bl\"].iloc[mci_idx]\n",
    "                    event = 1\n",
    "                else:\n",
    "                    time_to_event = df[\"Years_bl\"].iloc[-1] - df[\"Years_bl\"].iloc[mci_idx]\n",
    "                    event = 0\n",
    "                \n",
    "                imgs, tabs, times, mmse_vals = [], [], [], []\n",
    "                valid_visits = 0\n",
    "                \n",
    "                for _, visit in df.iterrows():\n",
    "                    image_path = visit[\"image_path\"].replace(\n",
    "                        \"/home/mason/ADNI_Dataset/\", \n",
    "                        \"./AD_Multimodal/ADNI_Dataset/\"\n",
    "                    )\n",
    "                    \n",
    "                    if not os.path.exists(image_path):\n",
    "                        continue\n",
    "                    \n",
    "                    img = Image.open(image_path).convert(\"RGB\")\n",
    "                    if self.transform:\n",
    "                        img = self.transform(img)\n",
    "                    \n",
    "                    imgs.append(img)\n",
    "                    tabs.append(visit[TEMPORAL_FEATURES + STATIC_FEATURES].values.astype(np.float32))\n",
    "                    times.append(visit[\"Years_bl\"])\n",
    "                    mmse_vals.append(visit[\"MMSE\"])\n",
    "                    valid_visits += 1\n",
    "                    \n",
    "                    if valid_visits >= max_seq_len:\n",
    "                        break\n",
    "                \n",
    "                if valid_visits < 2:\n",
    "                    continue\n",
    "                \n",
    "                pad_len = max_seq_len - len(imgs)\n",
    "                if pad_len > 0:\n",
    "                    for _ in range(pad_len):\n",
    "                        imgs.append(torch.zeros_like(imgs[-1]))\n",
    "                        tabs.append(np.zeros_like(tabs[-1]))\n",
    "                        times.append(times[-1])\n",
    "                        mmse_vals.append(0.0)\n",
    "                \n",
    "                self.sequences.append({\n",
    "                    'ptid': ptid,\n",
    "                    'imgs': torch.stack(imgs),\n",
    "                    'tabs': np.array(tabs, dtype=np.float32),\n",
    "                    'times': np.array(times, dtype=np.float32),\n",
    "                    'mmse': np.array(mmse_vals, dtype=np.float32),\n",
    "                    'seq_len': valid_visits,\n",
    "                    'time_to_event': time_to_event,\n",
    "                    'event': event\n",
    "                })\n",
    "                \n",
    "                processed += 1\n",
    "                \n",
    "            except Exception as e:\n",
    "                continue\n",
    "        \n",
    "        # ADDED: Standardize tabular features for stability\n",
    "        if len(self.sequences) > 0:\n",
    "            all_tabs = np.vstack([seq['tabs'] for seq in self.sequences])\n",
    "            self.scaler = StandardScaler()\n",
    "            self.scaler.fit(all_tabs)\n",
    "            \n",
    "            for seq in self.sequences:\n",
    "                seq['tabs'] = self.scaler.transform(seq['tabs']).astype(np.float32)\n",
    "        \n",
    "        print(f\"  Processed: {processed} valid patients\")\n",
    "        print(f\"  Skipped (not in valid set): {skipped_not_valid}\")\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.sequences)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        seq = self.sequences[idx]\n",
    "        return (\n",
    "            seq['imgs'], seq['tabs'], seq['times'], seq['mmse'],\n",
    "            seq['seq_len'], seq['time_to_event'], seq['event'], seq['ptid']\n",
    "        )\n",
    "\n",
    "# ============================================================================\n",
    "# MODEL: CONCATENATION INSTEAD OF TENSOR FUSION\n",
    "# ============================================================================\n",
    "\n",
    "class AttentionImageEncoder(nn.Module):\n",
    "    def __init__(self, out_dim=256):\n",
    "        super().__init__()\n",
    "        base = models.resnet18(pretrained=True)\n",
    "        for param in list(base.parameters())[:-20]:\n",
    "            param.requires_grad = False\n",
    "        \n",
    "        self.features = nn.Sequential(*list(base.children())[:-2])\n",
    "        self.attention = nn.Sequential(\n",
    "            nn.Conv2d(512, 256, 1),\n",
    "            nn.BatchNorm2d(256),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(256, 1, 1),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "        self.global_pool = nn.AdaptiveAvgPool2d(1)\n",
    "        self.proj = nn.Linear(512, out_dim)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        feats = self.features(x)\n",
    "        attn = self.attention(feats)\n",
    "        feats = feats * attn\n",
    "        pooled = self.global_pool(feats).view(x.size(0), -1)\n",
    "        return self.proj(pooled)\n",
    "\n",
    "class ConcatenationFusionAutoencoder(nn.Module):\n",
    "    \"\"\"\n",
    "    KEY DIFFERENCE: Uses simple concatenation [img; tab; time] \n",
    "    instead of tensor product fusion\n",
    "    \"\"\"\n",
    "    def __init__(self, tab_dim, config):\n",
    "        super().__init__()\n",
    "        self.config = config\n",
    "        \n",
    "        self.img_encoder = AttentionImageEncoder(out_dim=config['img_out_dim'])\n",
    "        \n",
    "        self.tab_encoder = nn.Sequential(\n",
    "            nn.Linear(tab_dim, 128),\n",
    "            nn.BatchNorm1d(128),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(config['dropout']),\n",
    "            nn.Linear(128, config['tab_out_dim']),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "        \n",
    "        self.time_encoder = nn.Sequential(\n",
    "            nn.Linear(1, 16),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "        \n",
    "        # CONCATENATION instead of tensor fusion\n",
    "        concat_dim = config['img_out_dim'] + config['tab_out_dim'] + 16\n",
    "        \n",
    "        self.concat_proj = nn.Sequential(\n",
    "            nn.Linear(concat_dim, config['latent_dim']),\n",
    "            nn.BatchNorm1d(config['latent_dim']),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "        \n",
    "        self.lstm = nn.LSTM(\n",
    "            input_size=config['latent_dim'],\n",
    "            hidden_size=config['lstm_hidden'],\n",
    "            num_layers=config['lstm_layers'],\n",
    "            batch_first=True,\n",
    "            dropout=config['dropout'] if config['lstm_layers'] > 1 else 0,\n",
    "            bidirectional=True\n",
    "        )\n",
    "        \n",
    "        self.temporal_proj = nn.Sequential(\n",
    "            nn.Linear(config['lstm_hidden'] * 2, config['latent_dim']),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "        \n",
    "        self.decoder = nn.Sequential(\n",
    "            nn.Linear(config['latent_dim'], 128),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(config['dropout']),\n",
    "            nn.Linear(128, tab_dim)\n",
    "        )\n",
    "        \n",
    "        self.survival_head = nn.Sequential(\n",
    "            nn.Linear(config['latent_dim'], 64),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(config['dropout']),\n",
    "            nn.Linear(64, 32),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(32, 1)\n",
    "        )\n",
    "        \n",
    "        self.mmse_head = nn.Sequential(\n",
    "            nn.Linear(config['latent_dim'], 32),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(32, 1)\n",
    "        )\n",
    "    \n",
    "    def encode_visit(self, img, tab, time):\n",
    "        v = self.img_encoder(img)\n",
    "        d = self.tab_encoder(tab)\n",
    "        t = self.time_encoder(time.unsqueeze(1))\n",
    "        \n",
    "        # SIMPLE CONCATENATION (not tensor fusion!)\n",
    "        concat = torch.cat([v, d, t], dim=1)\n",
    "        z = self.concat_proj(concat)\n",
    "        \n",
    "        return z\n",
    "    \n",
    "    def forward(self, img_seq, tab_seq, time_seq, seq_lengths):\n",
    "        batch_size, seq_len = img_seq.shape[:2]\n",
    "        \n",
    "        z_list = []\n",
    "        for t in range(seq_len):\n",
    "            z_t = self.encode_visit(img_seq[:, t], tab_seq[:, t], time_seq[:, t])\n",
    "            z_list.append(z_t)\n",
    "        \n",
    "        z_seq = torch.stack(z_list, dim=1)\n",
    "        \n",
    "        packed = nn.utils.rnn.pack_padded_sequence(\n",
    "            z_seq, seq_lengths.cpu(), batch_first=True, enforce_sorted=False\n",
    "        )\n",
    "        lstm_out, (h_n, c_n) = self.lstm(packed)\n",
    "        lstm_out, _ = nn.utils.rnn.pad_packed_sequence(lstm_out, batch_first=True)\n",
    "        \n",
    "        h_forward = h_n[-2]\n",
    "        h_backward = h_n[-1]\n",
    "        h_final = torch.cat([h_forward, h_backward], dim=1)\n",
    "        \n",
    "        z_final = self.temporal_proj(h_final)\n",
    "        \n",
    "        tab_recon = self.decoder(z_final)\n",
    "        risk_score = self.survival_head(z_final)\n",
    "        mmse_pred = self.mmse_head(z_final)\n",
    "        \n",
    "        return z_final, tab_recon, risk_score, mmse_pred\n",
    "\n",
    "# ============================================================================\n",
    "# LOSS & TRAINING\n",
    "# ============================================================================\n",
    "\n",
    "def cox_loss(risk_scores, times, events):\n",
    "    order = torch.argsort(times, descending=True)\n",
    "    risk_scores = risk_scores[order]\n",
    "    events = events[order]\n",
    "    log_risk = risk_scores.view(-1)\n",
    "    log_cumsum_hazard = torch.logcumsumexp(log_risk, dim=0)\n",
    "    loss = -(log_risk - log_cumsum_hazard) * events\n",
    "    return loss.sum() / (events.sum() + 1e-7)\n",
    "\n",
    "def train_epoch(model, loader, optimizer, config, device):\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    \n",
    "    for batch in loader:\n",
    "        imgs, tabs, times, mmse, seq_lens, t_event, event, _ = batch\n",
    "        \n",
    "        imgs = imgs.to(device)\n",
    "        tabs = torch.FloatTensor(tabs).to(device)\n",
    "        times = torch.FloatTensor(times).to(device)\n",
    "        mmse = torch.FloatTensor(mmse).to(device)\n",
    "        seq_lens = torch.LongTensor(seq_lens)\n",
    "        t_event = t_event.float().to(device)\n",
    "        event = event.float().to(device)\n",
    "        \n",
    "        last_tabs = torch.stack([tabs[i, seq_lens[i]-1] for i in range(len(seq_lens))])\n",
    "        last_mmse = torch.FloatTensor([mmse[i, seq_lens[i]-1] for i in range(len(seq_lens))]).to(device)\n",
    "        \n",
    "        z_final, tab_recon, risk_scores, mmse_pred = model(imgs, tabs, times, seq_lens)\n",
    "        \n",
    "        loss_recon = nn.MSELoss()(tab_recon, last_tabs)\n",
    "        loss_cox = cox_loss(risk_scores.squeeze(), t_event, event)\n",
    "        loss_mmse = nn.MSELoss()(mmse_pred.squeeze(), last_mmse)\n",
    "        \n",
    "        loss = (config['alpha_recon'] * loss_recon + \n",
    "                config['alpha_survival'] * loss_cox + \n",
    "                config['alpha_mmse'] * loss_mmse)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
    "        optimizer.step()\n",
    "        \n",
    "        total_loss += loss.item()\n",
    "    \n",
    "    return total_loss / len(loader)\n",
    "\n",
    "def validate(model, loader, device):\n",
    "    model.eval()\n",
    "    all_risks, all_times, all_events = [], [], []\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for batch in loader:\n",
    "            imgs, tabs, times, mmse, seq_lens, t_event, event, _ = batch\n",
    "            \n",
    "            imgs = imgs.to(device)\n",
    "            tabs = torch.FloatTensor(tabs).to(device)\n",
    "            times = torch.FloatTensor(times).to(device)\n",
    "            seq_lens = torch.LongTensor(seq_lens)\n",
    "            \n",
    "            _, _, risk_scores, _ = model(imgs, tabs, times, seq_lens)\n",
    "            \n",
    "            all_risks.extend(risk_scores.cpu().numpy().flatten())\n",
    "            all_times.extend(t_event.numpy())\n",
    "            all_events.extend(event.numpy())\n",
    "    \n",
    "    c_index = concordance_index(np.array(all_times), -np.array(all_risks), np.array(all_events).astype(bool))\n",
    "    return c_index\n",
    "\n",
    "# ============================================================================\n",
    "# EXPORT\n",
    "# ============================================================================\n",
    "\n",
    "def export_features(model, loader, device, output_path):\n",
    "    \"\"\"Export features with proper column structure and NaN handling\"\"\"\n",
    "    model.eval()\n",
    "    rows = []\n",
    "    \n",
    "    BASELINE_FEATURES = ['AGE', 'PTGENDER_encoded', 'PTEDUCAT', 'ADAS13']\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for batch in loader:\n",
    "            imgs, tabs, times, mmse, seq_lens, t_event, event, ptids = batch\n",
    "            \n",
    "            imgs = imgs.to(device)\n",
    "            tabs = torch.FloatTensor(tabs).to(device)\n",
    "            times = torch.FloatTensor(times).to(device)\n",
    "            seq_lens = torch.LongTensor(seq_lens)\n",
    "            \n",
    "            for i in range(len(ptids)):\n",
    "                slen = seq_lens[i].item()\n",
    "                \n",
    "                for t in range(slen):\n",
    "                    feat = model.encode_visit(imgs[i:i+1, t], tabs[i:i+1, t], times[i:i+1, t])\n",
    "                    feat_vals = feat[0].cpu().numpy()\n",
    "                    \n",
    "                    # CRITICAL: Check for NaN/Inf\n",
    "                    if np.any(np.isnan(feat_vals)) or np.any(np.isinf(feat_vals)):\n",
    "                        feat_vals = np.nan_to_num(feat_vals, nan=0.0, posinf=0.0, neginf=0.0)\n",
    "                    \n",
    "                    # Unscale tabular features\n",
    "                    tab_vals = loader.dataset.scaler.inverse_transform(\n",
    "                        tabs[i, t].cpu().numpy().reshape(1, -1)\n",
    "                    )[0]\n",
    "                    \n",
    "                    row = {\n",
    "                        \"PTID\": ptids[i],\n",
    "                        \"Years_bl\": float(times[i, t].cpu()),\n",
    "                        \"MMSE\": float(mmse[i, t]),\n",
    "                        \"time_to_event\": float(t_event[i]),\n",
    "                        \"event\": int(event[i]),\n",
    "                    }\n",
    "                    \n",
    "                    # Add clinical features\n",
    "                    tab_feature_names = TEMPORAL_FEATURES + STATIC_FEATURES\n",
    "                    for f in BASELINE_FEATURES:\n",
    "                        if f in tab_feature_names:\n",
    "                            idx = tab_feature_names.index(f)\n",
    "                            if idx < len(tab_vals):\n",
    "                                val = float(tab_vals[idx])\n",
    "                                if np.isnan(val) or np.isinf(val):\n",
    "                                    val = 0.0\n",
    "                                r_name = f.replace('_encoded', '')\n",
    "                                row[r_name] = val\n",
    "                    \n",
    "                    # Add ADAS13\n",
    "                    if 'ADAS13' in tab_feature_names:\n",
    "                        idx = tab_feature_names.index('ADAS13')\n",
    "                        if idx < len(tab_vals):\n",
    "                            val = float(tab_vals[idx])\n",
    "                            if np.isnan(val) or np.isinf(val):\n",
    "                                val = 0.0\n",
    "                            row['ADAS13'] = val\n",
    "                    \n",
    "                    # Add latent features\n",
    "                    for k in range(len(feat_vals)):\n",
    "                        row[f\"z_{k}\"] = float(feat_vals[k])\n",
    "                    \n",
    "                    rows.append(row)\n",
    "    \n",
    "    df = pd.DataFrame(rows).sort_values(['PTID', 'Years_bl'])\n",
    "    \n",
    "    # Final NaN/Inf check\n",
    "    numeric_cols = df.select_dtypes(include=[np.number]).columns\n",
    "    for col in numeric_cols:\n",
    "        if df[col].isna().any():\n",
    "            df[col].fillna(0, inplace=True)\n",
    "        if np.isinf(df[col]).any():\n",
    "            df[col] = df[col].replace([np.inf, -np.inf], 0)\n",
    "    \n",
    "    df.to_csv(output_path, index=False)\n",
    "    \n",
    "    print(f\"\\n✓ Exported to {output_path}\")\n",
    "    print(f\"  Patients: {df['PTID'].nunique()}\")\n",
    "    print(f\"  Visits: {len(df)}\")\n",
    "    print(f\"  Features: {len([c for c in df.columns if c.startswith('z_')])}\")\n",
    "    \n",
    "    return df\n",
    "\n",
    "# ============================================================================\n",
    "# MAIN\n",
    "# ============================================================================\n",
    "\n",
    "def main():\n",
    "    print(\"=\" * 80)\n",
    "    print(\"BENCHMARK 4: CONCATENATION FUSION (vs Tensor Fusion)\")\n",
    "    print(\"=\" * 80)\n",
    "    \n",
    "    device = CONFIG['device']\n",
    "    print(f\"\\nDevice: {device}\")\n",
    "    \n",
    "    # Load valid patients\n",
    "    print(\"\\nLoading valid patient list...\")\n",
    "    with open('VALID_PATIENTS.pkl', 'rb') as f:\n",
    "        VALID_PATIENTS = pickle.load(f)\n",
    "    print(f\"Valid patients: {len(VALID_PATIENTS)}\")\n",
    "    \n",
    "    manifest = pd.read_csv(\"./AD_Multimodal/TFN_AD/AD_Patient_Manifest.csv\")\n",
    "    \n",
    "    transform = transforms.Compose([\n",
    "        transforms.Resize((224, 224)),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "    ])\n",
    "    \n",
    "    dataset = SequenceDataset(manifest, VALID_PATIENTS, transform, max_seq_len=CONFIG['max_seq_len'])\n",
    "    print(f\"Total sequences: {len(dataset)}\")\n",
    "    \n",
    "    n_train = int(0.8 * len(dataset))\n",
    "    n_val = len(dataset) - n_train\n",
    "    train_dataset, val_dataset = torch.utils.data.random_split(\n",
    "        dataset, [n_train, n_val], generator=torch.Generator().manual_seed(42)\n",
    "    )\n",
    "    \n",
    "    train_loader = DataLoader(train_dataset, batch_size=CONFIG['batch_size'], shuffle=True, num_workers=0)\n",
    "    val_loader = DataLoader(val_dataset, batch_size=CONFIG['batch_size'], shuffle=False, num_workers=0)\n",
    "    \n",
    "    tab_dim = next(iter(train_loader))[1].shape[2]\n",
    "    \n",
    "    model = ConcatenationFusionAutoencoder(tab_dim, CONFIG).to(device)\n",
    "    optimizer = torch.optim.AdamW(model.parameters(), lr=CONFIG['lr'], weight_decay=CONFIG['weight_decay'])\n",
    "    scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='max', factor=0.5, patience=5)\n",
    "    \n",
    "    print(\"\\nTraining...\")\n",
    "    best_c_index = 0\n",
    "    patience_counter = 0\n",
    "    \n",
    "    for epoch in range(CONFIG['epochs']):\n",
    "        train_loss = train_epoch(model, train_loader, optimizer, CONFIG, device)\n",
    "        val_c_index = validate(model, val_loader, device)\n",
    "        \n",
    "        scheduler.step(val_c_index)\n",
    "        print(f\"Epoch {epoch+1}/{CONFIG['epochs']} - Loss: {train_loss:.4f}, C-index: {val_c_index:.4f}\")\n",
    "        \n",
    "        if val_c_index > best_c_index:\n",
    "            best_c_index = val_c_index\n",
    "            torch.save(model.state_dict(), 'concat_fusion_model.pth')\n",
    "            patience_counter = 0\n",
    "        else:\n",
    "            patience_counter += 1\n",
    "        \n",
    "        if patience_counter >= 15:\n",
    "            break\n",
    "    \n",
    "    model.load_state_dict(torch.load('concat_fusion_model.pth'))\n",
    "    full_loader = DataLoader(dataset, batch_size=CONFIG['batch_size'], shuffle=False, num_workers=0)\n",
    "    export_features(model, full_loader, device, \"concat_fusion_features.csv\")\n",
    "    \n",
    "    print(\"\\n\" + \"=\" * 80)\n",
    "    print(f\"✓ BEST C-INDEX: {best_c_index:.4f}\")\n",
    "    print(\"⚠️  This uses the SAME patient cohort as all other benchmarks\")\n",
    "    print(\"=\" * 80)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n",
    "# \"\"\"\n",
    "# Benchmark 4: Concatenation Fusion\n",
    "# Simple concatenation instead of tensor fusion\n",
    "\n",
    "# Shows that tensor fusion is superior to naive concatenation.\n",
    "# This is a critical ablation - proves your fusion method adds value!\n",
    "\n",
    "# Architecture:\n",
    "# - Same as thesis BUT: simple concatenation [img; tab] instead of tensor product\n",
    "# - Everything else identical (LSTM, autoencoder, etc.)\n",
    "# - Expected to be worse than thesis but better than single modality\n",
    "# \"\"\"\n",
    "\n",
    "# import torch\n",
    "# import torch.nn as nn\n",
    "# from torchvision import models, transforms\n",
    "# from torch.utils.data import Dataset, DataLoader\n",
    "# from PIL import Image\n",
    "# import pandas as pd\n",
    "# import numpy as np\n",
    "# import os\n",
    "# import pickle\n",
    "# from lifelines.utils import concordance_index\n",
    "# import warnings\n",
    "# warnings.filterwarnings('ignore')\n",
    "\n",
    "# CONFIG = {\n",
    "#     'latent_dim': 128,\n",
    "#     'img_out_dim': 256,\n",
    "#     'tab_out_dim': 64,\n",
    "#     'lstm_hidden': 128,\n",
    "#     'lstm_layers': 2,\n",
    "#     'dropout': 0.3,\n",
    "#     'lr': 5e-4,\n",
    "#     'weight_decay': 1e-4,\n",
    "#     'epochs': 100,\n",
    "#     'batch_size': 16,\n",
    "#     'max_seq_len': 10,\n",
    "#     'alpha_recon': 0.2,\n",
    "#     'alpha_survival': 0.6,\n",
    "#     'alpha_mmse': 0.2,\n",
    "#     'device': 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "# }\n",
    "\n",
    "# # ============================================================================\n",
    "# # FEATURE ENGINEERING (Same as thesis)\n",
    "# # ============================================================================\n",
    "\n",
    "# STATIC_FEATURES = [\n",
    "#     'age_bl', 'PTGENDER_encoded', 'PTEDUCAT', 'PTETHCAT_encoded', \n",
    "#     'PTRACCAT_encoded', 'PTMARRY_encoded'\n",
    "# ]\n",
    "\n",
    "# TEMPORAL_FEATURES = [\n",
    "#     'time_from_baseline', 'AGE', 'age_since_bl', 'mmse_slope', \n",
    "#     'adas13_slope', 'dx_progression', 'cog_decline_index', \n",
    "#     'visit_number', 'MMSE', 'ADAS13'\n",
    "# ]\n",
    "\n",
    "# def engineer_features(df):\n",
    "#     df = df.copy()\n",
    "#     df[\"time_from_baseline\"] = df[\"Years_bl\"] - df[\"Years_bl\"].iloc[0]\n",
    "#     df[\"age_bl\"] = df[\"AGE\"].iloc[0]\n",
    "#     df[\"age_since_bl\"] = df[\"AGE\"] - df[\"age_bl\"]\n",
    "#     df[\"mmse_slope\"] = df[\"MMSE\"].diff() / df[\"Years_bl\"].diff()\n",
    "#     df[\"adas13_slope\"] = df[\"ADAS13\"].diff() / df[\"Years_bl\"].diff()\n",
    "#     dx_map = {\"CN\": 0, \"MCI\": 1, \"AD\": 2, \"Dementia\": 2}\n",
    "#     df[\"dx_progression\"] = df[\"DX\"].map(dx_map).diff()\n",
    "#     df[\"cog_decline_index\"] = df[\"ADAS13\"] - df[\"MMSE\"]\n",
    "#     df[\"visit_number\"] = range(len(df))\n",
    "#     df['age_mmse_interaction'] = df['AGE'] * (30 - df['MMSE']) / 30\n",
    "#     df['education_cognitive_reserve'] = df['PTEDUCAT'] * df['MMSE'] / 30\n",
    "#     df['rapid_decline_flag'] = (df['mmse_slope'] < -2).astype(float)\n",
    "#     mmse_bins = [0, 20, 24, 30]\n",
    "#     df['mmse_severity'] = pd.cut(df['MMSE'], bins=mmse_bins, labels=[2, 1, 0]).astype(float)\n",
    "#     df['weighted_mmse_decline'] = df['mmse_slope'] * np.exp(-0.1 * df['time_from_baseline'])\n",
    "#     df['mmse_variability'] = df['MMSE'].rolling(window=3, min_periods=1).std()\n",
    "#     df['adas_mmse_discordance'] = np.abs(\n",
    "#         (df['ADAS13'] - df['ADAS13'].mean()) / (df['ADAS13'].std() + 1e-7) - \n",
    "#         (df['MMSE'] - df['MMSE'].mean()) / (df['MMSE'].std() + 1e-7)\n",
    "#     )\n",
    "#     df = df.fillna(0)\n",
    "#     return df\n",
    "\n",
    "# TEMPORAL_FEATURES.extend([\n",
    "#     'age_mmse_interaction', 'education_cognitive_reserve', 'rapid_decline_flag',\n",
    "#     'mmse_severity', 'weighted_mmse_decline', 'mmse_variability', 'adas_mmse_discordance'\n",
    "# ])\n",
    "\n",
    "# # ============================================================================\n",
    "# # DATASET (Same as thesis)\n",
    "# # ============================================================================\n",
    "\n",
    "# class SequenceDataset(Dataset):\n",
    "#     def __init__(self, manifest, valid_patients, transform=None, max_seq_len=10):\n",
    "#         self.sequences = []\n",
    "#         self.transform = transform\n",
    "#         self.max_seq_len = max_seq_len\n",
    "        \n",
    "#         manifest[\"path\"] = manifest[\"path\"].str.replace(\"\\\\\", \"/\", regex=False)\n",
    "#         manifest[\"path\"] = \"./AD_Multimodal/TFN_AD/\" + manifest[\"path\"]\n",
    "\n",
    "#         skipped_not_valid = 0\n",
    "#         processed = 0\n",
    "        \n",
    "#         for ptid in manifest['PTID'].unique():\n",
    "#             if ptid not in valid_patients:\n",
    "#                 skipped_not_valid += 1\n",
    "#                 continue\n",
    "                \n",
    "#             try:\n",
    "#                 patient_rows = manifest[manifest['PTID'] == ptid]\n",
    "#                 if len(patient_rows) == 0:\n",
    "#                     continue\n",
    "                \n",
    "#                 df = pd.read_pickle(patient_rows.iloc[0][\"path\"])\n",
    "#                 df = engineer_features(df)\n",
    "                \n",
    "#                 dx_seq = df[\"DX\"].tolist()\n",
    "#                 if \"MCI\" not in dx_seq:\n",
    "#                     continue\n",
    "                \n",
    "#                 mci_idx = dx_seq.index(\"MCI\")\n",
    "#                 ad_idx = next((i for i, x in enumerate(dx_seq[mci_idx+1:], start=mci_idx+1) \n",
    "#                               if x in [\"AD\", \"Dementia\"]), -1)\n",
    "                \n",
    "#                 if ad_idx != -1:\n",
    "#                     time_to_event = df[\"Years_bl\"].iloc[ad_idx]\n",
    "#                     event = 1\n",
    "#                 else:\n",
    "#                     time_to_event = df[\"Years_bl\"].iloc[-1]\n",
    "#                     event = 0\n",
    "                \n",
    "#                 imgs, tabs, times, mmse_vals = [], [], [], []\n",
    "#                 valid_visits = 0\n",
    "                \n",
    "#                 for _, visit in df.iterrows():\n",
    "#                     image_path = visit[\"image_path\"].replace(\n",
    "#                         \"/home/mason/ADNI_Dataset/\", \n",
    "#                         \"./AD_Multimodal/ADNI_Dataset/\"\n",
    "#                     )\n",
    "                    \n",
    "#                     if not os.path.exists(image_path):\n",
    "#                         continue\n",
    "                    \n",
    "#                     img = Image.open(image_path).convert(\"RGB\")\n",
    "#                     if self.transform:\n",
    "#                         img = self.transform(img)\n",
    "                    \n",
    "#                     imgs.append(img)\n",
    "#                     tabs.append(visit[TEMPORAL_FEATURES + STATIC_FEATURES].values.astype(np.float32))\n",
    "#                     times.append(visit[\"Years_bl\"])\n",
    "#                     mmse_vals.append(visit[\"MMSE\"])\n",
    "#                     valid_visits += 1\n",
    "                    \n",
    "#                     if valid_visits >= max_seq_len:\n",
    "#                         break\n",
    "                \n",
    "#                 if valid_visits < 2:\n",
    "#                     continue\n",
    "                \n",
    "#                 pad_len = max_seq_len - len(imgs)\n",
    "#                 if pad_len > 0:\n",
    "#                     for _ in range(pad_len):\n",
    "#                         imgs.append(torch.zeros_like(imgs[-1]))\n",
    "#                         tabs.append(np.zeros_like(tabs[-1]))\n",
    "#                         times.append(times[-1])\n",
    "#                         mmse_vals.append(0.0)\n",
    "                \n",
    "#                 self.sequences.append({\n",
    "#                     'ptid': ptid,\n",
    "#                     'imgs': torch.stack(imgs),\n",
    "#                     'tabs': np.array(tabs, dtype=np.float32),\n",
    "#                     'times': np.array(times, dtype=np.float32),\n",
    "#                     'mmse': np.array(mmse_vals, dtype=np.float32),\n",
    "#                     'seq_len': valid_visits,\n",
    "#                     'time_to_event': time_to_event,\n",
    "#                     'event': event\n",
    "#                 })\n",
    "\n",
    "#                 processed += 1\n",
    "                \n",
    "#             except Exception as e:\n",
    "#                 continue\n",
    "\n",
    "#         print(f\"  Processed: {processed} valid patients\")\n",
    "#         print(f\"  Skipped (not in valid set): {skipped_not_valid}\")\n",
    "    \n",
    "#     def __len__(self):\n",
    "#         return len(self.sequences)\n",
    "    \n",
    "#     def __getitem__(self, idx):\n",
    "#         seq = self.sequences[idx]\n",
    "#         return (\n",
    "#             seq['imgs'], seq['tabs'], seq['times'], seq['mmse'],\n",
    "#             seq['seq_len'], seq['time_to_event'], seq['event'], seq['ptid']\n",
    "#         )\n",
    "\n",
    "# # ============================================================================\n",
    "# # MODEL: CONCATENATION INSTEAD OF TENSOR FUSION\n",
    "# # ============================================================================\n",
    "\n",
    "# class AttentionImageEncoder(nn.Module):\n",
    "#     def __init__(self, out_dim=256):\n",
    "#         super().__init__()\n",
    "#         base = models.resnet18(pretrained=True)\n",
    "#         for param in list(base.parameters())[:-20]:\n",
    "#             param.requires_grad = False\n",
    "        \n",
    "#         self.features = nn.Sequential(*list(base.children())[:-2])\n",
    "#         self.attention = nn.Sequential(\n",
    "#             nn.Conv2d(512, 256, 1),\n",
    "#             nn.BatchNorm2d(256),\n",
    "#             nn.ReLU(),\n",
    "#             nn.Conv2d(256, 1, 1),\n",
    "#             nn.Sigmoid()\n",
    "#         )\n",
    "#         self.global_pool = nn.AdaptiveAvgPool2d(1)\n",
    "#         self.proj = nn.Linear(512, out_dim)\n",
    "    \n",
    "#     def forward(self, x):\n",
    "#         feats = self.features(x)\n",
    "#         attn = self.attention(feats)\n",
    "#         feats = feats * attn\n",
    "#         pooled = self.global_pool(feats).view(x.size(0), -1)\n",
    "#         return self.proj(pooled)\n",
    "\n",
    "# class ConcatenationFusionAutoencoder(nn.Module):\n",
    "#     \"\"\"\n",
    "#     KEY DIFFERENCE: Uses simple concatenation [img; tab; time] \n",
    "#     instead of tensor product fusion\n",
    "#     \"\"\"\n",
    "#     def __init__(self, tab_dim, config):\n",
    "#         super().__init__()\n",
    "#         self.config = config\n",
    "        \n",
    "#         self.img_encoder = AttentionImageEncoder(out_dim=config['img_out_dim'])\n",
    "        \n",
    "#         self.tab_encoder = nn.Sequential(\n",
    "#             nn.Linear(tab_dim, 128),\n",
    "#             nn.BatchNorm1d(128),\n",
    "#             nn.ReLU(),\n",
    "#             nn.Dropout(config['dropout']),\n",
    "#             nn.Linear(128, config['tab_out_dim']),\n",
    "#             nn.ReLU()\n",
    "#         )\n",
    "#         # self.tab_encoder = nn.Sequential(\n",
    "#         #     nn.Linear(tab_dim, 32),\n",
    "#         #     nn.ReLU(),\n",
    "#         #     nn.Dropout(config['dropout']),\n",
    "#         #     nn.Linear(32, 16),\n",
    "#         #     nn.ReLU()\n",
    "#         # )\n",
    "\n",
    "        \n",
    "#         self.time_encoder = nn.Sequential(\n",
    "#             nn.Linear(1, 16),\n",
    "#             nn.ReLU()\n",
    "#         )\n",
    "        \n",
    "#         # CONCATENATION instead of tensor fusion\n",
    "#         concat_dim = config['img_out_dim'] + config['tab_out_dim'] + 16\n",
    "#         #concat_dim = config['img_out_dim'] + 16 + 16\n",
    "\n",
    "        \n",
    "#         self.concat_proj = nn.Sequential(\n",
    "#             nn.Linear(concat_dim, config['latent_dim']),\n",
    "#             nn.BatchNorm1d(config['latent_dim']),\n",
    "#             nn.ReLU()\n",
    "#         )\n",
    "        \n",
    "#         self.lstm = nn.LSTM(\n",
    "#             input_size=config['latent_dim'],\n",
    "#             hidden_size=config['lstm_hidden'],\n",
    "#             num_layers=config['lstm_layers'],\n",
    "#             batch_first=True,\n",
    "#             dropout=config['dropout'] if config['lstm_layers'] > 1 else 0,\n",
    "#             bidirectional=True\n",
    "#         )\n",
    "        \n",
    "#         self.temporal_proj = nn.Sequential(\n",
    "#             nn.Linear(config['lstm_hidden'] * 2, config['latent_dim']),\n",
    "#             nn.ReLU()\n",
    "#         )\n",
    "        \n",
    "#         self.decoder = nn.Sequential(\n",
    "#             nn.Linear(config['latent_dim'], 128),\n",
    "#             nn.ReLU(),\n",
    "#             nn.Dropout(config['dropout']),\n",
    "#             nn.Linear(128, tab_dim)\n",
    "#         )\n",
    "        \n",
    "#         self.survival_head = nn.Sequential(\n",
    "#             nn.Linear(config['latent_dim'], 64),\n",
    "#             nn.ReLU(),\n",
    "#             nn.Dropout(config['dropout']),\n",
    "#             nn.Linear(64, 32),\n",
    "#             nn.ReLU(),\n",
    "#             nn.Linear(32, 1)\n",
    "#         )\n",
    "        \n",
    "#         self.mmse_head = nn.Sequential(\n",
    "#             nn.Linear(config['latent_dim'], 32),\n",
    "#             nn.ReLU(),\n",
    "#             nn.Linear(32, 1)\n",
    "#         )\n",
    "    \n",
    "#     def encode_visit(self, img, tab, time):\n",
    "#         v = self.img_encoder(img)\n",
    "#         d = self.tab_encoder(tab)\n",
    "#         t = self.time_encoder(time.unsqueeze(1))\n",
    "        \n",
    "#         # SIMPLE CONCATENATION (not tensor fusion!)\n",
    "#         concat = torch.cat([v, d, t], dim=1)\n",
    "#         z = self.concat_proj(concat)\n",
    "        \n",
    "#         return z\n",
    "    \n",
    "#     def forward(self, img_seq, tab_seq, time_seq, seq_lengths):\n",
    "#         batch_size, seq_len = img_seq.shape[:2]\n",
    "        \n",
    "#         z_list = []\n",
    "#         for t in range(seq_len):\n",
    "#             z_t = self.encode_visit(img_seq[:, t], tab_seq[:, t], time_seq[:, t])\n",
    "#             z_list.append(z_t)\n",
    "        \n",
    "#         z_seq = torch.stack(z_list, dim=1)\n",
    "        \n",
    "#         packed = nn.utils.rnn.pack_padded_sequence(\n",
    "#             z_seq, seq_lengths.cpu(), batch_first=True, enforce_sorted=False\n",
    "#         )\n",
    "#         lstm_out, (h_n, c_n) = self.lstm(packed)\n",
    "#         lstm_out, _ = nn.utils.rnn.pad_packed_sequence(lstm_out, batch_first=True)\n",
    "        \n",
    "#         h_forward = h_n[-2]\n",
    "#         h_backward = h_n[-1]\n",
    "#         h_final = torch.cat([h_forward, h_backward], dim=1)\n",
    "        \n",
    "#         z_final = self.temporal_proj(h_final)\n",
    "        \n",
    "#         tab_recon = self.decoder(z_final)\n",
    "#         risk_score = self.survival_head(z_final)\n",
    "#         mmse_pred = self.mmse_head(z_final)\n",
    "        \n",
    "#         return z_final, tab_recon, risk_score, mmse_pred\n",
    "\n",
    "# # ============================================================================\n",
    "# # LOSS & TRAINING (Same as thesis)\n",
    "# # ============================================================================\n",
    "\n",
    "# def cox_loss(risk_scores, times, events):\n",
    "#     order = torch.argsort(times, descending=True)\n",
    "#     risk_scores = risk_scores[order]\n",
    "#     events = events[order]\n",
    "#     log_risk = risk_scores.view(-1)\n",
    "#     log_cumsum_hazard = torch.logcumsumexp(log_risk, dim=0)\n",
    "#     loss = -(log_risk - log_cumsum_hazard) * events\n",
    "#     return loss.sum() / (events.sum() + 1e-7)\n",
    "\n",
    "# def train_epoch(model, loader, optimizer, config, device):\n",
    "#     model.train()\n",
    "#     total_loss = 0\n",
    "    \n",
    "#     for batch in loader:\n",
    "#         imgs, tabs, times, mmse, seq_lens, t_event, event, _ = batch\n",
    "        \n",
    "#         imgs = imgs.to(device)\n",
    "#         tabs = torch.FloatTensor(tabs).to(device)\n",
    "#         times = torch.FloatTensor(times).to(device)\n",
    "#         mmse = torch.FloatTensor(mmse).to(device)\n",
    "#         seq_lens = torch.LongTensor(seq_lens)\n",
    "#         t_event = t_event.float().to(device)\n",
    "#         event = event.float().to(device)\n",
    "        \n",
    "#         last_tabs = torch.stack([tabs[i, seq_lens[i]-1] for i in range(len(seq_lens))])\n",
    "#         last_mmse = torch.FloatTensor([mmse[i, seq_lens[i]-1] for i in range(len(seq_lens))]).to(device)\n",
    "        \n",
    "#         z_final, tab_recon, risk_scores, mmse_pred = model(imgs, tabs, times, seq_lens)\n",
    "        \n",
    "#         loss_recon = nn.MSELoss()(tab_recon, last_tabs)\n",
    "#         loss_cox = cox_loss(risk_scores.squeeze(), t_event, event)\n",
    "#         loss_mmse = nn.MSELoss()(mmse_pred.squeeze(), last_mmse)\n",
    "        \n",
    "#         loss = (config['alpha_recon'] * loss_recon + \n",
    "#                 config['alpha_survival'] * loss_cox + \n",
    "#                 config['alpha_mmse'] * loss_mmse)\n",
    "        \n",
    "#         optimizer.zero_grad()\n",
    "#         loss.backward()\n",
    "#         torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
    "#         optimizer.step()\n",
    "        \n",
    "#         total_loss += loss.item()\n",
    "    \n",
    "#     return total_loss / len(loader)\n",
    "\n",
    "# def validate(model, loader, device):\n",
    "#     model.eval()\n",
    "#     all_risks, all_times, all_events = [], [], []\n",
    "    \n",
    "#     with torch.no_grad():\n",
    "#         for batch in loader:\n",
    "#             imgs, tabs, times, mmse, seq_lens, t_event, event, _ = batch\n",
    "            \n",
    "#             imgs = imgs.to(device)\n",
    "#             tabs = torch.FloatTensor(tabs).to(device)\n",
    "#             times = torch.FloatTensor(times).to(device)\n",
    "#             seq_lens = torch.LongTensor(seq_lens)\n",
    "            \n",
    "#             _, _, risk_scores, _ = model(imgs, tabs, times, seq_lens)\n",
    "            \n",
    "#             all_risks.extend(risk_scores.cpu().numpy().flatten())\n",
    "#             all_times.extend(t_event.numpy())\n",
    "#             all_events.extend(event.numpy())\n",
    "    \n",
    "#     c_index = concordance_index(np.array(all_times), -np.array(all_risks), np.array(all_events).astype(bool))\n",
    "#     return c_index\n",
    "\n",
    "# # ============================================================================\n",
    "# # EXPORT\n",
    "# # ============================================================================\n",
    "\n",
    "# def export_features(model, loader, device, output_path):\n",
    "#     \"\"\"Export features with proper column structure\"\"\"\n",
    "#     model.eval()\n",
    "#     rows = []\n",
    "    \n",
    "#     BASELINE_FEATURES = ['AGE', 'PTGENDER_encoded', 'PTEDUCAT', 'ADAS13']\n",
    "    \n",
    "#     with torch.no_grad():\n",
    "#         for batch in loader:\n",
    "#             imgs, tabs, times, mmse, seq_lens, t_event, event, ptids = batch\n",
    "            \n",
    "#             imgs = imgs.to(device)\n",
    "#             tabs = torch.FloatTensor(tabs).to(device)\n",
    "#             times = torch.FloatTensor(times).to(device)\n",
    "#             seq_lens = torch.LongTensor(seq_lens)\n",
    "            \n",
    "#             batch_size, seq_len = imgs.shape[:2]\n",
    "            \n",
    "#             for i in range(len(ptids)):\n",
    "#                 slen = seq_lens[i].item()\n",
    "                \n",
    "#                 for t in range(slen):\n",
    "#                     img_t = imgs[i:i+1, t]\n",
    "#                     tab_t = tabs[i:i+1, t]\n",
    "#                     time_t = times[i:i+1, t]\n",
    "                    \n",
    "#                     z_visit = model.encode_visit(img_t, tab_t, time_t)\n",
    "#                     tab_vals = tabs[i, t].cpu().numpy()\n",
    "                    \n",
    "#                     row = {\n",
    "#                         \"PTID\": ptids[i],\n",
    "#                         \"Years_bl\": float(times[i, t].cpu()),\n",
    "#                         \"MMSE\": float(mmse[i, t]),\n",
    "#                         \"time_to_event\": float(t_event[i]),\n",
    "#                         \"event\": int(event[i]),\n",
    "#                     }\n",
    "                    \n",
    "#                     # Add clinical features with proper names\n",
    "#                     tab_feature_names = TEMPORAL_FEATURES + STATIC_FEATURES\n",
    "#                     for feat in BASELINE_FEATURES:\n",
    "#                         if feat in tab_feature_names:\n",
    "#                             idx = tab_feature_names.index(feat)\n",
    "#                             if idx < len(tab_vals):\n",
    "#                                 r_name = feat.replace('_encoded', '')\n",
    "#                                 row[r_name] = float(tab_vals[idx])\n",
    "                    \n",
    "#                     # Add ADAS13 from tab_vals if available\n",
    "#                     if 'ADAS13' in tab_feature_names:\n",
    "#                         idx = tab_feature_names.index('ADAS13')\n",
    "#                         if idx < len(tab_vals):\n",
    "#                             row['ADAS13'] = float(tab_vals[idx])\n",
    "                    \n",
    "#                     # Add latent features\n",
    "#                     z_vals = z_visit[0].cpu().numpy()\n",
    "#                     for k in range(len(z_vals)):\n",
    "#                         row[f\"z_{k}\"] = float(z_vals[k])\n",
    "                    \n",
    "#                     # # ZERO OUT TABULAR-LEAKAGE HALF\n",
    "#                     # z_vals[int(len(z_vals)*0.5):] = 0\n",
    "                    \n",
    "#                     rows.append(row)\n",
    "    \n",
    "#     df = pd.DataFrame(rows).sort_values(['PTID', 'Years_bl'])\n",
    "    \n",
    "#     # Ensure PTID is unique per row for grouping\n",
    "#     common_ptids = set(df['PTID'])\n",
    "#     df = df[df['PTID'].isin(common_ptids)]\n",
    "    \n",
    "#     df.to_csv(output_path, index=False)\n",
    "    \n",
    "#     print(f\"\\n✓ Exported to {output_path}\")\n",
    "#     print(f\"  Patients: {df['PTID'].nunique()}\")\n",
    "#     print(f\"  Visits: {len(df)}\")\n",
    "#     print(f\"  Latent features: {len([c for c in df.columns if c.startswith('z_')])}\")\n",
    "    \n",
    "#     return df\n",
    "\n",
    "# # ============================================================================\n",
    "# # MAIN\n",
    "# # ============================================================================\n",
    "\n",
    "# def main():\n",
    "#     print(\"=\" * 80)\n",
    "#     print(\"BENCHMARK 4: CONCATENATION FUSION (vs Tensor Fusion)\")\n",
    "#     print(\"=\" * 80)\n",
    "    \n",
    "#     device = CONFIG['device']\n",
    "#     manifest = pd.read_csv(\"./AD_Multimodal/TFN_AD/AD_Patient_Manifest.csv\")\n",
    "\n",
    "#     # Load valid patients\n",
    "#     print(\"\\nLoading valid patient list...\")\n",
    "#     with open('VALID_PATIENTS.pkl', 'rb') as f:\n",
    "#         VALID_PATIENTS = pickle.load(f)\n",
    "#     print(f\"Valid patients: {len(VALID_PATIENTS)}\")\n",
    "    \n",
    "#     transform = transforms.Compose([\n",
    "#         transforms.Resize((224, 224)),\n",
    "#         transforms.ToTensor(),\n",
    "#         transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "#     ])\n",
    "    \n",
    "#     dataset = SequenceDataset(manifest, VALID_PATIENTS, transform, max_seq_len=CONFIG['max_seq_len'])\n",
    "#     print(f\"Total sequences: {len(dataset)}\")\n",
    "    \n",
    "#     n_train = int(0.8 * len(dataset))\n",
    "#     n_val = len(dataset) - n_train\n",
    "#     train_dataset, val_dataset = torch.utils.data.random_split(\n",
    "#         dataset, [n_train, n_val], generator=torch.Generator().manual_seed(42)\n",
    "#     )\n",
    "    \n",
    "#     train_loader = DataLoader(train_dataset, batch_size=CONFIG['batch_size'], shuffle=True, num_workers=0)\n",
    "#     val_loader = DataLoader(val_dataset, batch_size=CONFIG['batch_size'], shuffle=False, num_workers=0)\n",
    "    \n",
    "#     tab_dim = next(iter(train_loader))[1].shape[2]\n",
    "    \n",
    "#     model = ConcatenationFusionAutoencoder(tab_dim, CONFIG).to(device)\n",
    "#     optimizer = torch.optim.AdamW(model.parameters(), lr=CONFIG['lr'], weight_decay=CONFIG['weight_decay'])\n",
    "#     scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='max', factor=0.5, patience=5)\n",
    "    \n",
    "#     print(\"\\nTraining...\")\n",
    "#     best_c_index = 0\n",
    "#     patience_counter = 0\n",
    "    \n",
    "#     for epoch in range(CONFIG['epochs']):\n",
    "#         train_loss = train_epoch(model, train_loader, optimizer, CONFIG, device)\n",
    "#         val_c_index = validate(model, val_loader, device)\n",
    "        \n",
    "#         scheduler.step(val_c_index)\n",
    "#         print(f\"Epoch {epoch+1}/{CONFIG['epochs']} - Loss: {train_loss:.4f}, C-index: {val_c_index:.4f}\")\n",
    "        \n",
    "#         if val_c_index > best_c_index:\n",
    "#             best_c_index = val_c_index\n",
    "#             torch.save(model.state_dict(), 'concat_fusion_model.pth')\n",
    "#             patience_counter = 0\n",
    "#         else:\n",
    "#             patience_counter += 1\n",
    "        \n",
    "#         if patience_counter >= 15:\n",
    "#             break\n",
    "    \n",
    "#     model.load_state_dict(torch.load('concat_fusion_model.pth'))\n",
    "#     full_loader = DataLoader(dataset, batch_size=CONFIG['batch_size'], shuffle=False, num_workers=0)\n",
    "#     export_features(model, full_loader, device, \"concat_fusion_features.csv\")\n",
    "    \n",
    "#     print(\"\\n\" + \"=\" * 80)\n",
    "#     print(f\"✓ BEST C-INDEX: {best_c_index:.4f}\")\n",
    "#     print(\"=\" * 80)\n",
    "\n",
    "# if __name__ == \"__main__\":\n",
    "#     main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "721b5c54-5a18-4a43-b5f6-de3c6c32fabd",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
