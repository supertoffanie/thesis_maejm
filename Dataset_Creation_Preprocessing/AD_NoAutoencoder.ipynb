{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ba5ad773-ed3f-48dd-830f-287c8c7a1f00",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "BENCHMARK 5: NO AUTOENCODER (Direct Tensor Fusion)\n",
      "================================================================================\n",
      "\n",
      "Device: cuda\n",
      "\n",
      "Loading valid patient list...\n",
      "Valid patients: 161\n",
      "  Processed: 161 valid patients\n",
      "  Skipped (not in valid set): 221\n",
      "Total sequences: 161\n",
      "\n",
      "Training...\n",
      "Epoch 1/100 - Loss: 2.2208, C-index: 0.8350\n",
      "Epoch 2/100 - Loss: 1.9429, C-index: 0.8026\n",
      "Epoch 3/100 - Loss: 1.6458, C-index: 0.8188\n",
      "Epoch 4/100 - Loss: 1.5022, C-index: 0.8026\n",
      "Epoch 5/100 - Loss: 1.2587, C-index: 0.7961\n",
      "Epoch 6/100 - Loss: 1.4411, C-index: 0.7929\n",
      "Epoch 7/100 - Loss: 1.0963, C-index: 0.8220\n",
      "Epoch 8/100 - Loss: 1.1245, C-index: 0.8544\n",
      "Epoch 9/100 - Loss: 1.0396, C-index: 0.8576\n",
      "Epoch 10/100 - Loss: 0.8288, C-index: 0.8544\n",
      "Epoch 11/100 - Loss: 0.9557, C-index: 0.8414\n",
      "Epoch 12/100 - Loss: 0.8235, C-index: 0.8285\n",
      "Epoch 13/100 - Loss: 0.9103, C-index: 0.8317\n",
      "Epoch 14/100 - Loss: 0.8518, C-index: 0.8317\n",
      "Epoch 15/100 - Loss: 0.7392, C-index: 0.8382\n",
      "Epoch 16/100 - Loss: 0.9989, C-index: 0.8350\n",
      "Epoch 17/100 - Loss: 0.7214, C-index: 0.8252\n",
      "Epoch 18/100 - Loss: 0.7929, C-index: 0.8155\n",
      "Epoch 19/100 - Loss: 0.6770, C-index: 0.8026\n",
      "Epoch 20/100 - Loss: 0.7010, C-index: 0.8188\n",
      "Epoch 21/100 - Loss: 0.5596, C-index: 0.8026\n",
      "Epoch 22/100 - Loss: 0.7035, C-index: 0.8058\n",
      "Epoch 23/100 - Loss: 0.6627, C-index: 0.8123\n",
      "Epoch 24/100 - Loss: 0.5789, C-index: 0.8220\n",
      "\n",
      "✓ Exported to no_autoencoder_features.csv\n",
      "  Patients: 161\n",
      "  Visits: 948\n",
      "  Features: 256\n",
      "  Total NaN replaced: 0\n",
      "  Total Inf replaced: 0\n",
      "  ✓ Data quality check PASSED - no NaN/Inf values\n",
      "\n",
      "================================================================================\n",
      "✓ BEST C-INDEX: 0.8576\n",
      "⚠️  This uses the SAME patient cohort as all other benchmarks\n",
      "✓ R-COMPATIBLE: All NaN/Inf values handled, features standardized\n",
      "================================================================================\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Benchmark 5: No Autoencoder (Direct Features)\n",
    "Uses tensor fusion but NO autoencoder latent encoding\n",
    "\n",
    "FIXED VERSION:\n",
    "- Uses VALID_PATIENTS.pkl for consistent patient cohort\n",
    "- Survival time measured from MCI diagnosis (consistent)\n",
    "- CRITICAL R FIXES: Proper feature standardization, NaN/Inf handling\n",
    "- Factor level consistency for PTID\n",
    "\n",
    "Shows that the autoencoder's learned representations add value.\n",
    "Direct features → LSTM → Risk (no reconstruction loss, no latent bottleneck)\n",
    "\n",
    "Architecture:\n",
    "- Tensor fusion ✓\n",
    "- LSTM ✓\n",
    "- Autoencoder ✗ (removed)\n",
    "- Just direct supervised learning\n",
    "\"\"\"\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torchvision import models, transforms\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from PIL import Image\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import pickle\n",
    "from lifelines.utils import concordance_index\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "CONFIG = {\n",
    "    'img_out_dim': 256,\n",
    "    'tab_out_dim': 64,\n",
    "    'lstm_hidden': 128,\n",
    "    'lstm_layers': 2,\n",
    "    'dropout': 0.3,\n",
    "    'lr': 5e-4,\n",
    "    'weight_decay': 1e-4,\n",
    "    'epochs': 100,\n",
    "    'batch_size': 16,\n",
    "    'max_seq_len': 10,\n",
    "    'device': 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "}\n",
    "\n",
    "# ============================================================================\n",
    "# FEATURE ENGINEERING (Same as thesis)\n",
    "# ============================================================================\n",
    "\n",
    "STATIC_FEATURES = [\n",
    "    'age_bl', 'PTGENDER_encoded', 'PTEDUCAT', 'PTETHCAT_encoded', \n",
    "    'PTRACCAT_encoded', 'PTMARRY_encoded'\n",
    "]\n",
    "\n",
    "TEMPORAL_FEATURES = [\n",
    "    'time_from_baseline', 'AGE', 'age_since_bl', 'mmse_slope', \n",
    "    'adas13_slope', 'dx_progression', 'cog_decline_index', \n",
    "    'visit_number', 'MMSE', 'ADAS13'\n",
    "]\n",
    "\n",
    "def engineer_features(df):\n",
    "    df = df.copy()\n",
    "    df[\"time_from_baseline\"] = df[\"Years_bl\"] - df[\"Years_bl\"].iloc[0]\n",
    "    df[\"age_bl\"] = df[\"AGE\"].iloc[0]\n",
    "    df[\"age_since_bl\"] = df[\"AGE\"] - df[\"age_bl\"]\n",
    "    df[\"mmse_slope\"] = df[\"MMSE\"].diff() / df[\"Years_bl\"].diff()\n",
    "    df[\"adas13_slope\"] = df[\"ADAS13\"].diff() / df[\"Years_bl\"].diff()\n",
    "    dx_map = {\"CN\": 0, \"MCI\": 1, \"AD\": 2, \"Dementia\": 2}\n",
    "    df[\"dx_progression\"] = df[\"DX\"].map(dx_map).diff()\n",
    "    df[\"cog_decline_index\"] = df[\"ADAS13\"] - df[\"MMSE\"]\n",
    "    df[\"visit_number\"] = range(len(df))\n",
    "    df['age_mmse_interaction'] = df['AGE'] * (30 - df['MMSE']) / 30\n",
    "    df['education_cognitive_reserve'] = df['PTEDUCAT'] * df['MMSE'] / 30\n",
    "    df['rapid_decline_flag'] = (df['mmse_slope'] < -2).astype(float)\n",
    "    mmse_bins = [0, 20, 24, 30]\n",
    "    df['mmse_severity'] = pd.cut(df['MMSE'], bins=mmse_bins, labels=[2, 1, 0]).astype(float)\n",
    "    df['weighted_mmse_decline'] = df['mmse_slope'] * np.exp(-0.1 * df['time_from_baseline'])\n",
    "    df['mmse_variability'] = df['MMSE'].rolling(window=3, min_periods=1).std()\n",
    "    df['adas_mmse_discordance'] = np.abs(\n",
    "        (df['ADAS13'] - df['ADAS13'].mean()) / (df['ADAS13'].std() + 1e-7) - \n",
    "        (df['MMSE'] - df['MMSE'].mean()) / (df['MMSE'].std() + 1e-7)\n",
    "    )\n",
    "    df = df.fillna(0)\n",
    "    return df\n",
    "\n",
    "TEMPORAL_FEATURES.extend([\n",
    "    'age_mmse_interaction', 'education_cognitive_reserve', 'rapid_decline_flag',\n",
    "    'mmse_severity', 'weighted_mmse_decline', 'mmse_variability', 'adas_mmse_discordance'\n",
    "])\n",
    "\n",
    "# ============================================================================\n",
    "# DATASET\n",
    "# ============================================================================\n",
    "\n",
    "class SequenceDataset(Dataset):\n",
    "    def __init__(self, manifest, valid_patients, transform=None, max_seq_len=10):\n",
    "        self.sequences = []\n",
    "        self.transform = transform\n",
    "        self.max_seq_len = max_seq_len\n",
    "        \n",
    "        manifest[\"path\"] = manifest[\"path\"].str.replace(\"\\\\\", \"/\", regex=False)\n",
    "        manifest[\"path\"] = \"./AD_Multimodal/TFN_AD/\" + manifest[\"path\"]\n",
    "        \n",
    "        processed = 0\n",
    "        skipped_not_valid = 0\n",
    "        \n",
    "        for ptid in manifest['PTID'].unique():\n",
    "            # CRITICAL: Only process valid patients\n",
    "            if ptid not in valid_patients:\n",
    "                skipped_not_valid += 1\n",
    "                continue\n",
    "            \n",
    "            try:\n",
    "                patient_rows = manifest[manifest['PTID'] == ptid]\n",
    "                if len(patient_rows) == 0:\n",
    "                    continue\n",
    "                \n",
    "                df = pd.read_pickle(patient_rows.iloc[0][\"path\"])\n",
    "                df = engineer_features(df)\n",
    "                \n",
    "                dx_seq = df[\"DX\"].tolist()\n",
    "                if \"MCI\" not in dx_seq:\n",
    "                    continue\n",
    "                \n",
    "                # FIXED: Time from MCI diagnosis\n",
    "                mci_idx = dx_seq.index(\"MCI\")\n",
    "                ad_idx = next((i for i, x in enumerate(dx_seq[mci_idx+1:], start=mci_idx+1) \n",
    "                              if x in [\"AD\", \"Dementia\"]), -1)\n",
    "                \n",
    "                if ad_idx != -1:\n",
    "                    time_to_event = df[\"Years_bl\"].iloc[ad_idx] - df[\"Years_bl\"].iloc[mci_idx]\n",
    "                    event = 1\n",
    "                else:\n",
    "                    time_to_event = df[\"Years_bl\"].iloc[-1] - df[\"Years_bl\"].iloc[mci_idx]\n",
    "                    event = 0\n",
    "                \n",
    "                imgs, tabs, times, mmse_vals = [], [], [], []\n",
    "                valid_visits = 0\n",
    "                \n",
    "                for _, visit in df.iterrows():\n",
    "                    image_path = visit[\"image_path\"].replace(\n",
    "                        \"/home/mason/ADNI_Dataset/\", \n",
    "                        \"./AD_Multimodal/ADNI_Dataset/\"\n",
    "                    )\n",
    "                    \n",
    "                    if not os.path.exists(image_path):\n",
    "                        continue\n",
    "                    \n",
    "                    img = Image.open(image_path).convert(\"RGB\")\n",
    "                    if self.transform:\n",
    "                        img = self.transform(img)\n",
    "                    \n",
    "                    imgs.append(img)\n",
    "                    tabs.append(visit[TEMPORAL_FEATURES + STATIC_FEATURES].values.astype(np.float32))\n",
    "                    times.append(visit[\"Years_bl\"])\n",
    "                    mmse_vals.append(visit[\"MMSE\"])\n",
    "                    valid_visits += 1\n",
    "                    \n",
    "                    if valid_visits >= max_seq_len:\n",
    "                        break\n",
    "                \n",
    "                if valid_visits < 2:\n",
    "                    continue\n",
    "                \n",
    "                pad_len = max_seq_len - len(imgs)\n",
    "                if pad_len > 0:\n",
    "                    for _ in range(pad_len):\n",
    "                        imgs.append(torch.zeros_like(imgs[-1]))\n",
    "                        tabs.append(np.zeros_like(tabs[-1]))\n",
    "                        times.append(times[-1])\n",
    "                        mmse_vals.append(0.0)\n",
    "                \n",
    "                self.sequences.append({\n",
    "                    'ptid': ptid,\n",
    "                    'imgs': torch.stack(imgs),\n",
    "                    'tabs': np.array(tabs, dtype=np.float32),\n",
    "                    'times': np.array(times, dtype=np.float32),\n",
    "                    'mmse': np.array(mmse_vals, dtype=np.float32),\n",
    "                    'seq_len': valid_visits,\n",
    "                    'time_to_event': time_to_event,\n",
    "                    'event': event\n",
    "                })\n",
    "                \n",
    "                processed += 1\n",
    "                \n",
    "            except Exception as e:\n",
    "                continue\n",
    "        \n",
    "        # CRITICAL R FIX: Standardize tabular features for numerical stability\n",
    "        if len(self.sequences) > 0:\n",
    "            all_tabs = np.vstack([seq['tabs'] for seq in self.sequences])\n",
    "            self.scaler = StandardScaler()\n",
    "            self.scaler.fit(all_tabs)\n",
    "            \n",
    "            for seq in self.sequences:\n",
    "                seq['tabs'] = self.scaler.transform(seq['tabs']).astype(np.float32)\n",
    "        \n",
    "        print(f\"  Processed: {processed} valid patients\")\n",
    "        print(f\"  Skipped (not in valid set): {skipped_not_valid}\")\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.sequences)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        seq = self.sequences[idx]\n",
    "        return (\n",
    "            seq['imgs'], seq['tabs'], seq['times'], seq['mmse'],\n",
    "            seq['seq_len'], seq['time_to_event'], seq['event'], seq['ptid']\n",
    "        )\n",
    "\n",
    "# ============================================================================\n",
    "# MODEL: NO AUTOENCODER\n",
    "# ============================================================================\n",
    "\n",
    "class TensorFusion(nn.Module):\n",
    "    def __init__(self, v_dim, d_dim, t_dim, proj_dim=None, dropout=0.1):\n",
    "        super().__init__()\n",
    "        self.v_dim = v_dim\n",
    "        self.d_dim = d_dim\n",
    "        self.t_dim = t_dim\n",
    "        self.output_dim = (v_dim + 1) * (d_dim + 1) * (t_dim + 1)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        \n",
    "        if proj_dim:\n",
    "            self.proj = nn.Linear(self.output_dim, proj_dim)\n",
    "        else:\n",
    "            self.proj = None\n",
    "    \n",
    "    def forward(self, v, d, t):\n",
    "        batch_size = v.shape[0]\n",
    "        v_1 = torch.cat([v, torch.ones(batch_size, 1, device=v.device)], dim=1)\n",
    "        d_1 = torch.cat([d, torch.ones(batch_size, 1, device=d.device)], dim=1)\n",
    "        t_1 = torch.cat([t, torch.ones(batch_size, 1, device=t.device)], dim=1)\n",
    "        \n",
    "        fusion = torch.einsum('bi,bj,bk->bijk', v_1, d_1, t_1)\n",
    "        fusion = fusion.view(batch_size, -1)\n",
    "        fusion = self.dropout(fusion)\n",
    "        \n",
    "        if self.proj:\n",
    "            fusion = self.proj(fusion)\n",
    "        \n",
    "        return fusion\n",
    "\n",
    "class AttentionImageEncoder(nn.Module):\n",
    "    def __init__(self, out_dim=256):\n",
    "        super().__init__()\n",
    "        base = models.resnet18(pretrained=True)\n",
    "        for param in list(base.parameters())[:-20]:\n",
    "            param.requires_grad = False\n",
    "        \n",
    "        self.features = nn.Sequential(*list(base.children())[:-2])\n",
    "        self.attention = nn.Sequential(\n",
    "            nn.Conv2d(512, 256, 1),\n",
    "            nn.BatchNorm2d(256),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(256, 1, 1),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "        self.global_pool = nn.AdaptiveAvgPool2d(1)\n",
    "        self.proj = nn.Linear(512, out_dim)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        feats = self.features(x)\n",
    "        attn = self.attention(feats)\n",
    "        feats = feats * attn\n",
    "        pooled = self.global_pool(feats).view(x.size(0), -1)\n",
    "        return self.proj(pooled)\n",
    "\n",
    "class NoAutoencoderModel(nn.Module):\n",
    "    \"\"\"\n",
    "    KEY DIFFERENCE: No autoencoder, no reconstruction loss\n",
    "    Direct tensor fusion → LSTM → Risk prediction\n",
    "    \"\"\"\n",
    "    def __init__(self, tab_dim, config):\n",
    "        super().__init__()\n",
    "        self.config = config\n",
    "        \n",
    "        self.img_encoder = AttentionImageEncoder(out_dim=config['img_out_dim'])\n",
    "        \n",
    "        self.tab_encoder = nn.Sequential(\n",
    "            nn.Linear(tab_dim, 128),\n",
    "            nn.BatchNorm1d(128),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(config['dropout']),\n",
    "            nn.Linear(128, config['tab_out_dim']),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "        \n",
    "        self.time_encoder = nn.Sequential(\n",
    "            nn.Linear(1, 16),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "        \n",
    "        # Tensor fusion (kept from thesis)\n",
    "        self.fusion = TensorFusion(\n",
    "            v_dim=config['img_out_dim'],\n",
    "            d_dim=config['tab_out_dim'],\n",
    "            t_dim=16,\n",
    "            dropout=config['dropout']\n",
    "        )\n",
    "        \n",
    "        # Direct projection (NO autoencoder bottleneck)\n",
    "        fusion_dim = (config['img_out_dim'] + 1) * (config['tab_out_dim'] + 1) * 17\n",
    "        self.fusion_proj = nn.Sequential(\n",
    "            nn.Linear(fusion_dim, 256),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "        \n",
    "        # LSTM\n",
    "        self.lstm = nn.LSTM(\n",
    "            input_size=256,\n",
    "            hidden_size=config['lstm_hidden'],\n",
    "            num_layers=config['lstm_layers'],\n",
    "            batch_first=True,\n",
    "            dropout=config['dropout'] if config['lstm_layers'] > 1 else 0,\n",
    "            bidirectional=True\n",
    "        )\n",
    "        \n",
    "        # Direct to risk prediction (NO decoder)\n",
    "        self.risk_head = nn.Sequential(\n",
    "            nn.Linear(config['lstm_hidden'] * 2, 64),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(config['dropout']),\n",
    "            nn.Linear(64, 1)\n",
    "        )\n",
    "    \n",
    "    def encode_visit(self, img, tab, time):\n",
    "        v = self.img_encoder(img)\n",
    "        d = self.tab_encoder(tab)\n",
    "        t = self.time_encoder(time.unsqueeze(1))\n",
    "        \n",
    "        z = self.fusion(v, d, t)\n",
    "        z = z.view(z.size(0), -1)\n",
    "        z = self.fusion_proj(z)\n",
    "        \n",
    "        return z\n",
    "    \n",
    "    def forward(self, img_seq, tab_seq, time_seq, seq_lengths):\n",
    "        batch_size, seq_len = img_seq.shape[:2]\n",
    "        \n",
    "        z_list = []\n",
    "        for t in range(seq_len):\n",
    "            z_t = self.encode_visit(img_seq[:, t], tab_seq[:, t], time_seq[:, t])\n",
    "            z_list.append(z_t)\n",
    "        \n",
    "        z_seq = torch.stack(z_list, dim=1)\n",
    "        \n",
    "        packed = nn.utils.rnn.pack_padded_sequence(\n",
    "            z_seq, seq_lengths.cpu(), batch_first=True, enforce_sorted=False\n",
    "        )\n",
    "        lstm_out, (h_n, c_n) = self.lstm(packed)\n",
    "        \n",
    "        h_forward = h_n[-2]\n",
    "        h_backward = h_n[-1]\n",
    "        h_final = torch.cat([h_forward, h_backward], dim=1)\n",
    "        \n",
    "        risk_score = self.risk_head(h_final)\n",
    "        \n",
    "        return risk_score\n",
    "\n",
    "# ============================================================================\n",
    "# LOSS & TRAINING\n",
    "# ============================================================================\n",
    "\n",
    "def cox_loss(risk_scores, times, events):\n",
    "    order = torch.argsort(times, descending=True)\n",
    "    risk_scores = risk_scores[order]\n",
    "    events = events[order]\n",
    "    log_risk = risk_scores.view(-1)\n",
    "    log_cumsum_hazard = torch.logcumsumexp(log_risk, dim=0)\n",
    "    loss = -(log_risk - log_cumsum_hazard) * events\n",
    "    return loss.sum() / (events.sum() + 1e-7)\n",
    "\n",
    "def train_epoch(model, loader, optimizer, device):\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    \n",
    "    for batch in loader:\n",
    "        imgs, tabs, times, mmse, seq_lens, t_event, event, _ = batch\n",
    "        \n",
    "        imgs = imgs.to(device)\n",
    "        tabs = torch.FloatTensor(tabs).to(device)\n",
    "        times = torch.FloatTensor(times).to(device)\n",
    "        seq_lens = torch.LongTensor(seq_lens)\n",
    "        t_event = t_event.float().to(device)\n",
    "        event = event.float().to(device)\n",
    "        \n",
    "        risk_scores = model(imgs, tabs, times, seq_lens)\n",
    "        \n",
    "        # Only Cox loss (no reconstruction, no MMSE prediction)\n",
    "        loss = cox_loss(risk_scores.squeeze(), t_event, event)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
    "        optimizer.step()\n",
    "        \n",
    "        total_loss += loss.item()\n",
    "    \n",
    "    return total_loss / len(loader)\n",
    "\n",
    "def validate(model, loader, device):\n",
    "    model.eval()\n",
    "    all_risks, all_times, all_events = [], [], []\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for batch in loader:\n",
    "            imgs, tabs, times, mmse, seq_lens, t_event, event, _ = batch\n",
    "            \n",
    "            imgs = imgs.to(device)\n",
    "            tabs = torch.FloatTensor(tabs).to(device)\n",
    "            times = torch.FloatTensor(times).to(device)\n",
    "            seq_lens = torch.LongTensor(seq_lens)\n",
    "            \n",
    "            risk_scores = model(imgs, tabs, times, seq_lens)\n",
    "            \n",
    "            all_risks.extend(risk_scores.cpu().numpy().flatten())\n",
    "            all_times.extend(t_event.numpy())\n",
    "            all_events.extend(event.numpy())\n",
    "    \n",
    "    c_index = concordance_index(np.array(all_times), -np.array(all_risks), np.array(all_events).astype(bool))\n",
    "    return c_index\n",
    "\n",
    "# ============================================================================\n",
    "# EXPORT (WITH ALL R COMPATIBILITY FIXES)\n",
    "# ============================================================================\n",
    "\n",
    "def export_features(model, loader, device, output_path):\n",
    "    \"\"\"Export features with CRITICAL R compatibility fixes\"\"\"\n",
    "    model.eval()\n",
    "    rows = []\n",
    "    \n",
    "    BASELINE_FEATURES = ['AGE', 'PTGENDER_encoded', 'PTEDUCAT', 'ADAS13']\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for batch in loader:\n",
    "            imgs, tabs, times, mmse, seq_lens, t_event, event, ptids = batch\n",
    "            \n",
    "            imgs = imgs.to(device)\n",
    "            tabs = torch.FloatTensor(tabs).to(device)\n",
    "            times = torch.FloatTensor(times).to(device)\n",
    "            seq_lens = torch.LongTensor(seq_lens)\n",
    "            \n",
    "            for i in range(len(ptids)):\n",
    "                slen = seq_lens[i].item()\n",
    "                \n",
    "                for t in range(slen):\n",
    "                    feat = model.encode_visit(imgs[i:i+1, t], tabs[i:i+1, t], times[i:i+1, t])\n",
    "                    feat_vals = feat[0].cpu().numpy()\n",
    "                    \n",
    "                    # CRITICAL FIX 1: NaN/Inf handling\n",
    "                    if np.any(np.isnan(feat_vals)) or np.any(np.isinf(feat_vals)):\n",
    "                        print(f\"WARNING: NaN/Inf in patient {ptids[i]} visit {t} - replacing with 0\")\n",
    "                        feat_vals = np.nan_to_num(feat_vals, nan=0.0, posinf=0.0, neginf=0.0)\n",
    "                    \n",
    "                    # Unscale tabular features\n",
    "                    tab_vals = loader.dataset.scaler.inverse_transform(\n",
    "                        tabs[i, t].cpu().numpy().reshape(1, -1)\n",
    "                    )[0]\n",
    "                    \n",
    "                    row = {\n",
    "                        \"PTID\": ptids[i],\n",
    "                        \"Years_bl\": float(times[i, t].cpu()),\n",
    "                        \"MMSE\": float(mmse[i, t]),\n",
    "                        \"time_to_event\": float(t_event[i]),\n",
    "                        \"event\": int(event[i]),\n",
    "                    }\n",
    "                    \n",
    "                    # Add clinical features with proper names\n",
    "                    tab_feature_names = TEMPORAL_FEATURES + STATIC_FEATURES\n",
    "                    for f in BASELINE_FEATURES:\n",
    "                        if f in tab_feature_names:\n",
    "                            idx = tab_feature_names.index(f)\n",
    "                            if idx < len(tab_vals):\n",
    "                                val = float(tab_vals[idx])\n",
    "                                # CRITICAL FIX 2: Check tabular features too\n",
    "                                if np.isnan(val) or np.isinf(val):\n",
    "                                    val = 0.0\n",
    "                                r_name = f.replace('_encoded', '')\n",
    "                                row[r_name] = val\n",
    "                    \n",
    "                    # Add ADAS13\n",
    "                    if 'ADAS13' in tab_feature_names:\n",
    "                        idx = tab_feature_names.index('ADAS13')\n",
    "                        if idx < len(tab_vals):\n",
    "                            val = float(tab_vals[idx])\n",
    "                            if np.isnan(val) or np.isinf(val):\n",
    "                                val = 0.0\n",
    "                            row['ADAS13'] = val\n",
    "                    \n",
    "                    # Add learned features (call them z_ for consistency)\n",
    "                    for k in range(len(feat_vals)):\n",
    "                        row[f\"z_{k}\"] = float(feat_vals[k])\n",
    "                    \n",
    "                    rows.append(row)\n",
    "    \n",
    "    df = pd.DataFrame(rows).sort_values(['PTID', 'Years_bl'])\n",
    "    \n",
    "    # CRITICAL FIX 3: Final NaN/Inf check on entire dataframe\n",
    "    numeric_cols = df.select_dtypes(include=[np.number]).columns\n",
    "    nan_count = 0\n",
    "    inf_count = 0\n",
    "    \n",
    "    for col in numeric_cols:\n",
    "        if df[col].isna().any():\n",
    "            nan_count += df[col].isna().sum()\n",
    "            print(f\"WARNING: {df[col].isna().sum()} NaN in column {col} - filling with 0\")\n",
    "            df[col].fillna(0, inplace=True)\n",
    "        if np.isinf(df[col]).any():\n",
    "            inf_count += np.isinf(df[col]).sum()\n",
    "            print(f\"WARNING: {np.isinf(df[col]).sum()} Inf in column {col} - replacing with 0\")\n",
    "            df[col] = df[col].replace([np.inf, -np.inf], 0)\n",
    "    \n",
    "    df.to_csv(output_path, index=False)\n",
    "    \n",
    "    print(f\"\\n✓ Exported to {output_path}\")\n",
    "    print(f\"  Patients: {df['PTID'].nunique()}\")\n",
    "    print(f\"  Visits: {len(df)}\")\n",
    "    print(f\"  Features: {len([c for c in df.columns if c.startswith('z_')])}\")\n",
    "    print(f\"  Total NaN replaced: {nan_count}\")\n",
    "    print(f\"  Total Inf replaced: {inf_count}\")\n",
    "    \n",
    "    if nan_count == 0 and inf_count == 0:\n",
    "        print(\"  ✓ Data quality check PASSED - no NaN/Inf values\")\n",
    "    \n",
    "    return df\n",
    "\n",
    "# ============================================================================\n",
    "# MAIN\n",
    "# ============================================================================\n",
    "\n",
    "def main():\n",
    "    print(\"=\" * 80)\n",
    "    print(\"BENCHMARK 5: NO AUTOENCODER (Direct Tensor Fusion)\")\n",
    "    print(\"=\" * 80)\n",
    "    \n",
    "    device = CONFIG['device']\n",
    "    print(f\"\\nDevice: {device}\")\n",
    "    \n",
    "    # Load valid patients\n",
    "    print(\"\\nLoading valid patient list...\")\n",
    "    with open('VALID_PATIENTS.pkl', 'rb') as f:\n",
    "        VALID_PATIENTS = pickle.load(f)\n",
    "    print(f\"Valid patients: {len(VALID_PATIENTS)}\")\n",
    "    \n",
    "    manifest = pd.read_csv(\"./AD_Multimodal/TFN_AD/AD_Patient_Manifest.csv\")\n",
    "    \n",
    "    transform = transforms.Compose([\n",
    "        transforms.Resize((224, 224)),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "    ])\n",
    "    \n",
    "    dataset = SequenceDataset(manifest, VALID_PATIENTS, transform, max_seq_len=CONFIG['max_seq_len'])\n",
    "    print(f\"Total sequences: {len(dataset)}\")\n",
    "    \n",
    "    n_train = int(0.8 * len(dataset))\n",
    "    n_val = len(dataset) - n_train\n",
    "    train_dataset, val_dataset = torch.utils.data.random_split(\n",
    "        dataset, [n_train, n_val], generator=torch.Generator().manual_seed(42)\n",
    "    )\n",
    "    \n",
    "    train_loader = DataLoader(train_dataset, batch_size=CONFIG['batch_size'], shuffle=True, num_workers=0)\n",
    "    val_loader = DataLoader(val_dataset, batch_size=CONFIG['batch_size'], shuffle=False, num_workers=0)\n",
    "    \n",
    "    tab_dim = next(iter(train_loader))[1].shape[2]\n",
    "    \n",
    "    model = NoAutoencoderModel(tab_dim, CONFIG).to(device)\n",
    "    optimizer = torch.optim.AdamW(model.parameters(), lr=CONFIG['lr'], weight_decay=CONFIG['weight_decay'])\n",
    "    scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='max', factor=0.5, patience=5)\n",
    "    \n",
    "    print(\"\\nTraining...\")\n",
    "    best_c_index = 0\n",
    "    patience_counter = 0\n",
    "    \n",
    "    for epoch in range(CONFIG['epochs']):\n",
    "        train_loss = train_epoch(model, train_loader, optimizer, device)\n",
    "        val_c_index = validate(model, val_loader, device)\n",
    "        \n",
    "        scheduler.step(val_c_index)\n",
    "        print(f\"Epoch {epoch+1}/{CONFIG['epochs']} - Loss: {train_loss:.4f}, C-index: {val_c_index:.4f}\")\n",
    "        \n",
    "        if val_c_index > best_c_index:\n",
    "            best_c_index = val_c_index\n",
    "            torch.save(model.state_dict(), 'no_autoencoder_model.pth')\n",
    "            patience_counter = 0\n",
    "        else:\n",
    "            patience_counter += 1\n",
    "        \n",
    "        if patience_counter >= 15:\n",
    "            break\n",
    "    \n",
    "    model.load_state_dict(torch.load('no_autoencoder_model.pth'))\n",
    "    full_loader = DataLoader(dataset, batch_size=CONFIG['batch_size'], shuffle=False, num_workers=0)\n",
    "    export_features(model, full_loader, device, \"no_autoencoder_features.csv\")\n",
    "    \n",
    "    print(\"\\n\" + \"=\" * 80)\n",
    "    print(f\"✓ BEST C-INDEX: {best_c_index:.4f}\")\n",
    "    print(\"⚠️  This uses the SAME patient cohort as all other benchmarks\")\n",
    "    print(\"✓ R-COMPATIBLE: All NaN/Inf values handled, features standardized\")\n",
    "    print(\"=\" * 80)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n",
    "# \"\"\"\n",
    "# Benchmark 5: No Autoencoder (Direct Features)\n",
    "# Uses tensor fusion but NO autoencoder latent encoding\n",
    "\n",
    "# Shows that the autoencoder's learned representations add value.\n",
    "# Direct features → LSTM → Risk (no reconstruction loss, no latent bottleneck)\n",
    "\n",
    "# Architecture:\n",
    "# - Tensor fusion ✓\n",
    "# - LSTM ✓\n",
    "# - Autoencoder ✗ (removed)\n",
    "# - Just direct supervised learning\n",
    "# \"\"\"\n",
    "\n",
    "# import torch\n",
    "# import torch.nn as nn\n",
    "# from torchvision import models, transforms\n",
    "# from torch.utils.data import Dataset, DataLoader\n",
    "# from PIL import Image\n",
    "# import pandas as pd\n",
    "# import numpy as np\n",
    "# import os\n",
    "# import pickle\n",
    "# from lifelines.utils import concordance_index\n",
    "# import warnings\n",
    "# warnings.filterwarnings('ignore')\n",
    "\n",
    "# CONFIG = {\n",
    "#     'img_out_dim': 256,\n",
    "#     'tab_out_dim': 64,\n",
    "#     'lstm_hidden': 128,\n",
    "#     'lstm_layers': 2,\n",
    "#     'dropout': 0.3,\n",
    "#     'lr': 5e-4,\n",
    "#     'weight_decay': 1e-4,\n",
    "#     'epochs': 100,\n",
    "#     'batch_size': 16,\n",
    "#     'max_seq_len': 10,\n",
    "#     'device': 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "# }\n",
    "\n",
    "# # ============================================================================\n",
    "# # FEATURE ENGINEERING (Same as thesis)\n",
    "# # ============================================================================\n",
    "\n",
    "# STATIC_FEATURES = [\n",
    "#     'age_bl', 'PTGENDER_encoded', 'PTEDUCAT', 'PTETHCAT_encoded', \n",
    "#     'PTRACCAT_encoded', 'PTMARRY_encoded'\n",
    "# ]\n",
    "\n",
    "# TEMPORAL_FEATURES = [\n",
    "#     'time_from_baseline', 'AGE', 'age_since_bl', 'mmse_slope', \n",
    "#     'adas13_slope', 'dx_progression', 'cog_decline_index', \n",
    "#     'visit_number', 'MMSE', 'ADAS13'\n",
    "# ]\n",
    "\n",
    "# def engineer_features(df):\n",
    "#     df = df.copy()\n",
    "#     df[\"time_from_baseline\"] = df[\"Years_bl\"] - df[\"Years_bl\"].iloc[0]\n",
    "#     df[\"age_bl\"] = df[\"AGE\"].iloc[0]\n",
    "#     df[\"age_since_bl\"] = df[\"AGE\"] - df[\"age_bl\"]\n",
    "#     df[\"mmse_slope\"] = df[\"MMSE\"].diff() / df[\"Years_bl\"].diff()\n",
    "#     df[\"adas13_slope\"] = df[\"ADAS13\"].diff() / df[\"Years_bl\"].diff()\n",
    "#     dx_map = {\"CN\": 0, \"MCI\": 1, \"AD\": 2, \"Dementia\": 2}\n",
    "#     df[\"dx_progression\"] = df[\"DX\"].map(dx_map).diff()\n",
    "#     df[\"cog_decline_index\"] = df[\"ADAS13\"] - df[\"MMSE\"]\n",
    "#     df[\"visit_number\"] = range(len(df))\n",
    "#     df['age_mmse_interaction'] = df['AGE'] * (30 - df['MMSE']) / 30\n",
    "#     df['education_cognitive_reserve'] = df['PTEDUCAT'] * df['MMSE'] / 30\n",
    "#     df['rapid_decline_flag'] = (df['mmse_slope'] < -2).astype(float)\n",
    "#     mmse_bins = [0, 20, 24, 30]\n",
    "#     df['mmse_severity'] = pd.cut(df['MMSE'], bins=mmse_bins, labels=[2, 1, 0]).astype(float)\n",
    "#     df['weighted_mmse_decline'] = df['mmse_slope'] * np.exp(-0.1 * df['time_from_baseline'])\n",
    "#     df['mmse_variability'] = df['MMSE'].rolling(window=3, min_periods=1).std()\n",
    "#     df['adas_mmse_discordance'] = np.abs(\n",
    "#         (df['ADAS13'] - df['ADAS13'].mean()) / (df['ADAS13'].std() + 1e-7) - \n",
    "#         (df['MMSE'] - df['MMSE'].mean()) / (df['MMSE'].std() + 1e-7)\n",
    "#     )\n",
    "#     df = df.fillna(0)\n",
    "#     return df\n",
    "\n",
    "# TEMPORAL_FEATURES.extend([\n",
    "#     'age_mmse_interaction', 'education_cognitive_reserve', 'rapid_decline_flag',\n",
    "#     'mmse_severity', 'weighted_mmse_decline', 'mmse_variability', 'adas_mmse_discordance'\n",
    "# ])\n",
    "\n",
    "# # ============================================================================\n",
    "# # DATASET (Same as thesis)\n",
    "# # ============================================================================\n",
    "\n",
    "# class SequenceDataset(Dataset):\n",
    "#     def __init__(self, manifest, valid_patients, transform=None, max_seq_len=10):\n",
    "#         self.sequences = []\n",
    "#         self.transform = transform\n",
    "#         self.max_seq_len = max_seq_len\n",
    "        \n",
    "#         manifest[\"path\"] = manifest[\"path\"].str.replace(\"\\\\\", \"/\", regex=False)\n",
    "#         manifest[\"path\"] = \"./AD_Multimodal/TFN_AD/\" + manifest[\"path\"]\n",
    "        \n",
    "#         skipped_not_valid = 0\n",
    "#         processed = 0\n",
    "        \n",
    "#         for ptid in manifest['PTID'].unique():\n",
    "#             if ptid not in valid_patients:\n",
    "#                 skipped_not_valid += 1\n",
    "#                 continue\n",
    "#             try:\n",
    "#                 patient_rows = manifest[manifest['PTID'] == ptid]\n",
    "#                 if len(patient_rows) == 0:\n",
    "#                     continue\n",
    "                \n",
    "#                 df = pd.read_pickle(patient_rows.iloc[0][\"path\"])\n",
    "#                 df = engineer_features(df)\n",
    "                \n",
    "#                 dx_seq = df[\"DX\"].tolist()\n",
    "#                 if \"MCI\" not in dx_seq:\n",
    "#                     continue\n",
    "                \n",
    "#                 mci_idx = dx_seq.index(\"MCI\")\n",
    "#                 ad_idx = next((i for i, x in enumerate(dx_seq[mci_idx+1:], start=mci_idx+1) \n",
    "#                               if x in [\"AD\", \"Dementia\"]), -1)\n",
    "                \n",
    "#                 if ad_idx != -1:\n",
    "#                     time_to_event = df[\"Years_bl\"].iloc[ad_idx]\n",
    "#                     event = 1\n",
    "#                 else:\n",
    "#                     time_to_event = df[\"Years_bl\"].iloc[-1]\n",
    "#                     event = 0\n",
    "                \n",
    "#                 imgs, tabs, times, mmse_vals = [], [], [], []\n",
    "#                 valid_visits = 0\n",
    "                \n",
    "#                 for _, visit in df.iterrows():\n",
    "#                     image_path = visit[\"image_path\"].replace(\n",
    "#                         \"/home/mason/ADNI_Dataset/\", \n",
    "#                         \"./AD_Multimodal/ADNI_Dataset/\"\n",
    "#                     )\n",
    "                    \n",
    "#                     if not os.path.exists(image_path):\n",
    "#                         continue\n",
    "                    \n",
    "#                     img = Image.open(image_path).convert(\"RGB\")\n",
    "#                     if self.transform:\n",
    "#                         img = self.transform(img)\n",
    "                    \n",
    "#                     imgs.append(img)\n",
    "#                     tabs.append(visit[TEMPORAL_FEATURES + STATIC_FEATURES].values.astype(np.float32))\n",
    "#                     times.append(visit[\"Years_bl\"])\n",
    "#                     mmse_vals.append(visit[\"MMSE\"])\n",
    "#                     valid_visits += 1\n",
    "                    \n",
    "#                     if valid_visits >= max_seq_len:\n",
    "#                         break\n",
    "                \n",
    "#                 if valid_visits < 2:\n",
    "#                     continue\n",
    "                \n",
    "#                 pad_len = max_seq_len - len(imgs)\n",
    "#                 if pad_len > 0:\n",
    "#                     for _ in range(pad_len):\n",
    "#                         imgs.append(torch.zeros_like(imgs[-1]))\n",
    "#                         tabs.append(np.zeros_like(tabs[-1]))\n",
    "#                         times.append(times[-1])\n",
    "#                         mmse_vals.append(0.0)\n",
    "                \n",
    "#                 self.sequences.append({\n",
    "#                     'ptid': ptid,\n",
    "#                     'imgs': torch.stack(imgs),\n",
    "#                     'tabs': np.array(tabs, dtype=np.float32),\n",
    "#                     'times': np.array(times, dtype=np.float32),\n",
    "#                     'mmse': np.array(mmse_vals, dtype=np.float32),\n",
    "#                     'seq_len': valid_visits,\n",
    "#                     'time_to_event': time_to_event,\n",
    "#                     'event': event\n",
    "#                 })\n",
    "\n",
    "#                 processed += 1\n",
    "                \n",
    "#             except Exception as e:\n",
    "#                 continue\n",
    "                \n",
    "#         print(f\"  Processed: {processed} valid patients\")\n",
    "#         print(f\"  Skipped (not in valid set): {skipped_not_valid}\")\n",
    "    \n",
    "#     def __len__(self):\n",
    "#         return len(self.sequences)\n",
    "    \n",
    "#     def __getitem__(self, idx):\n",
    "#         seq = self.sequences[idx]\n",
    "#         return (\n",
    "#             seq['imgs'], seq['tabs'], seq['times'], seq['mmse'],\n",
    "#             seq['seq_len'], seq['time_to_event'], seq['event'], seq['ptid']\n",
    "#         )\n",
    "\n",
    "# # ============================================================================\n",
    "# # MODEL: NO AUTOENCODER\n",
    "# # ============================================================================\n",
    "\n",
    "# class TensorFusion(nn.Module):\n",
    "#     def __init__(self, v_dim, d_dim, t_dim, proj_dim=None, dropout=0.1):\n",
    "#         super().__init__()\n",
    "#         self.v_dim = v_dim\n",
    "#         self.d_dim = d_dim\n",
    "#         self.t_dim = t_dim\n",
    "#         self.output_dim = (v_dim + 1) * (d_dim + 1) * (t_dim + 1)\n",
    "#         self.dropout = nn.Dropout(dropout)\n",
    "        \n",
    "#         if proj_dim:\n",
    "#             self.proj = nn.Linear(self.output_dim, proj_dim)\n",
    "#         else:\n",
    "#             self.proj = None\n",
    "    \n",
    "#     def forward(self, v, d, t):\n",
    "#         batch_size = v.shape[0]\n",
    "#         v_1 = torch.cat([v, torch.ones(batch_size, 1, device=v.device)], dim=1)\n",
    "#         d_1 = torch.cat([d, torch.ones(batch_size, 1, device=d.device)], dim=1)\n",
    "#         t_1 = torch.cat([t, torch.ones(batch_size, 1, device=t.device)], dim=1)\n",
    "        \n",
    "#         fusion = torch.einsum('bi,bj,bk->bijk', v_1, d_1, t_1)\n",
    "#         fusion = fusion.view(batch_size, -1)\n",
    "#         fusion = self.dropout(fusion)\n",
    "        \n",
    "#         if self.proj:\n",
    "#             fusion = self.proj(fusion)\n",
    "        \n",
    "#         return fusion\n",
    "\n",
    "# class AttentionImageEncoder(nn.Module):\n",
    "#     def __init__(self, out_dim=256):\n",
    "#         super().__init__()\n",
    "#         base = models.resnet18(pretrained=True)\n",
    "#         for param in list(base.parameters())[:-20]:\n",
    "#             param.requires_grad = False\n",
    "        \n",
    "#         self.features = nn.Sequential(*list(base.children())[:-2])\n",
    "#         self.attention = nn.Sequential(\n",
    "#             nn.Conv2d(512, 256, 1),\n",
    "#             nn.BatchNorm2d(256),\n",
    "#             nn.ReLU(),\n",
    "#             nn.Conv2d(256, 1, 1),\n",
    "#             nn.Sigmoid()\n",
    "#         )\n",
    "#         self.global_pool = nn.AdaptiveAvgPool2d(1)\n",
    "#         self.proj = nn.Linear(512, out_dim)\n",
    "    \n",
    "#     def forward(self, x):\n",
    "#         feats = self.features(x)\n",
    "#         attn = self.attention(feats)\n",
    "#         feats = feats * attn\n",
    "#         pooled = self.global_pool(feats).view(x.size(0), -1)\n",
    "#         return self.proj(pooled)\n",
    "\n",
    "# class NoAutoencoderModel(nn.Module):\n",
    "#     \"\"\"\n",
    "#     KEY DIFFERENCE: No autoencoder, no reconstruction loss\n",
    "#     Direct tensor fusion → LSTM → Risk prediction\n",
    "#     \"\"\"\n",
    "#     def __init__(self, tab_dim, config):\n",
    "#         super().__init__()\n",
    "#         self.config = config\n",
    "        \n",
    "#         self.img_encoder = AttentionImageEncoder(out_dim=config['img_out_dim'])\n",
    "        \n",
    "#         self.tab_encoder = nn.Sequential(\n",
    "#             nn.Linear(tab_dim, 128),\n",
    "#             nn.BatchNorm1d(128),\n",
    "#             nn.ReLU(),\n",
    "#             nn.Dropout(config['dropout']),\n",
    "#             nn.Linear(128, config['tab_out_dim']),\n",
    "#             nn.ReLU()\n",
    "#         )\n",
    "        \n",
    "#         self.time_encoder = nn.Sequential(\n",
    "#             nn.Linear(1, 16),\n",
    "#             nn.ReLU()\n",
    "#         )\n",
    "        \n",
    "#         # Tensor fusion (kept from thesis)\n",
    "#         self.fusion = TensorFusion(\n",
    "#             v_dim=config['img_out_dim'],\n",
    "#             d_dim=config['tab_out_dim'],\n",
    "#             t_dim=16,\n",
    "#             dropout=config['dropout']\n",
    "#         )\n",
    "        \n",
    "#         # Direct projection (NO autoencoder bottleneck)\n",
    "#         fusion_dim = (config['img_out_dim'] + 1) * (config['tab_out_dim'] + 1) * 17\n",
    "#         self.fusion_proj = nn.Sequential(\n",
    "#             nn.Linear(fusion_dim, 256),  # Direct to LSTM input\n",
    "#             nn.ReLU()\n",
    "#         )\n",
    "        \n",
    "#         # LSTM\n",
    "#         self.lstm = nn.LSTM(\n",
    "#             input_size=256,\n",
    "#             hidden_size=config['lstm_hidden'],\n",
    "#             num_layers=config['lstm_layers'],\n",
    "#             batch_first=True,\n",
    "#             dropout=config['dropout'] if config['lstm_layers'] > 1 else 0,\n",
    "#             bidirectional=True\n",
    "#         )\n",
    "        \n",
    "#         # Direct to risk prediction (NO decoder)\n",
    "#         self.risk_head = nn.Sequential(\n",
    "#             nn.Linear(config['lstm_hidden'] * 2, 64),\n",
    "#             nn.ReLU(),\n",
    "#             nn.Dropout(config['dropout']),\n",
    "#             nn.Linear(64, 1)\n",
    "#         )\n",
    "    \n",
    "#     def encode_visit(self, img, tab, time):\n",
    "#         v = self.img_encoder(img)\n",
    "#         d = self.tab_encoder(tab)\n",
    "#         t = self.time_encoder(time.unsqueeze(1))\n",
    "        \n",
    "#         z = self.fusion(v, d, t)\n",
    "#         z = z.view(z.size(0), -1)\n",
    "#         z = self.fusion_proj(z)\n",
    "        \n",
    "#         return z\n",
    "    \n",
    "#     def forward(self, img_seq, tab_seq, time_seq, seq_lengths):\n",
    "#         batch_size, seq_len = img_seq.shape[:2]\n",
    "        \n",
    "#         z_list = []\n",
    "#         for t in range(seq_len):\n",
    "#             z_t = self.encode_visit(img_seq[:, t], tab_seq[:, t], time_seq[:, t])\n",
    "#             z_list.append(z_t)\n",
    "        \n",
    "#         z_seq = torch.stack(z_list, dim=1)\n",
    "        \n",
    "#         packed = nn.utils.rnn.pack_padded_sequence(\n",
    "#             z_seq, seq_lengths.cpu(), batch_first=True, enforce_sorted=False\n",
    "#         )\n",
    "#         lstm_out, (h_n, c_n) = self.lstm(packed)\n",
    "        \n",
    "#         h_forward = h_n[-2]\n",
    "#         h_backward = h_n[-1]\n",
    "#         h_final = torch.cat([h_forward, h_backward], dim=1)\n",
    "        \n",
    "#         risk_score = self.risk_head(h_final)\n",
    "        \n",
    "#         return risk_score\n",
    "\n",
    "# # ============================================================================\n",
    "# # LOSS & TRAINING\n",
    "# # ============================================================================\n",
    "\n",
    "# def cox_loss(risk_scores, times, events):\n",
    "#     order = torch.argsort(times, descending=True)\n",
    "#     risk_scores = risk_scores[order]\n",
    "#     events = events[order]\n",
    "#     log_risk = risk_scores.view(-1)\n",
    "#     log_cumsum_hazard = torch.logcumsumexp(log_risk, dim=0)\n",
    "#     loss = -(log_risk - log_cumsum_hazard) * events\n",
    "#     return loss.sum() / (events.sum() + 1e-7)\n",
    "\n",
    "# def train_epoch(model, loader, optimizer, device):\n",
    "#     model.train()\n",
    "#     total_loss = 0\n",
    "    \n",
    "#     for batch in loader:\n",
    "#         imgs, tabs, times, mmse, seq_lens, t_event, event, _ = batch\n",
    "        \n",
    "#         imgs = imgs.to(device)\n",
    "#         tabs = torch.FloatTensor(tabs).to(device)\n",
    "#         times = torch.FloatTensor(times).to(device)\n",
    "#         seq_lens = torch.LongTensor(seq_lens)\n",
    "#         t_event = t_event.float().to(device)\n",
    "#         event = event.float().to(device)\n",
    "        \n",
    "#         risk_scores = model(imgs, tabs, times, seq_lens)\n",
    "        \n",
    "#         # Only Cox loss (no reconstruction, no MMSE prediction)\n",
    "#         loss = cox_loss(risk_scores.squeeze(), t_event, event)\n",
    "        \n",
    "#         optimizer.zero_grad()\n",
    "#         loss.backward()\n",
    "#         torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
    "#         optimizer.step()\n",
    "        \n",
    "#         total_loss += loss.item()\n",
    "    \n",
    "#     return total_loss / len(loader)\n",
    "\n",
    "# def validate(model, loader, device):\n",
    "#     model.eval()\n",
    "#     all_risks, all_times, all_events = [], [], []\n",
    "    \n",
    "#     with torch.no_grad():\n",
    "#         for batch in loader:\n",
    "#             imgs, tabs, times, mmse, seq_lens, t_event, event, _ = batch\n",
    "            \n",
    "#             imgs = imgs.to(device)\n",
    "#             tabs = torch.FloatTensor(tabs).to(device)\n",
    "#             times = torch.FloatTensor(times).to(device)\n",
    "#             seq_lens = torch.LongTensor(seq_lens)\n",
    "            \n",
    "#             risk_scores = model(imgs, tabs, times, seq_lens)\n",
    "            \n",
    "#             all_risks.extend(risk_scores.cpu().numpy().flatten())\n",
    "#             all_times.extend(t_event.numpy())\n",
    "#             all_events.extend(event.numpy())\n",
    "    \n",
    "#     c_index = concordance_index(np.array(all_times), -np.array(all_risks), np.array(all_events).astype(bool))\n",
    "#     return c_index\n",
    "\n",
    "# # ============================================================================\n",
    "# # EXPORT\n",
    "# # ============================================================================\n",
    "\n",
    "# def export_features(model, loader, device, output_path):\n",
    "#     \"\"\"Export features with proper column structure and NaN handling\"\"\"\n",
    "#     model.eval()\n",
    "#     rows = []\n",
    "    \n",
    "#     BASELINE_FEATURES = ['AGE', 'PTGENDER_encoded', 'PTEDUCAT', 'ADAS13']\n",
    "    \n",
    "#     with torch.no_grad():\n",
    "#         for batch in loader:\n",
    "#             imgs, tabs, times, mmse, seq_lens, t_event, event, ptids = batch\n",
    "            \n",
    "#             imgs = imgs.to(device)\n",
    "#             tabs = torch.FloatTensor(tabs).to(device)\n",
    "#             times = torch.FloatTensor(times).to(device)\n",
    "#             seq_lens = torch.LongTensor(seq_lens)\n",
    "            \n",
    "#             for i in range(len(ptids)):\n",
    "#                 slen = seq_lens[i].item()\n",
    "                \n",
    "#                 for t in range(slen):\n",
    "#                     feat = model.encode_visit(imgs[i:i+1, t], tabs[i:i+1, t], times[i:i+1, t])\n",
    "#                     feat_vals = feat[0].cpu().numpy()\n",
    "                    \n",
    "#                     # *** CRITICAL FIX: Check for NaN/Inf ***\n",
    "#                     if np.any(np.isnan(feat_vals)) or np.any(np.isinf(feat_vals)):\n",
    "#                         print(f\"WARNING: NaN/Inf detected for patient {ptids[i]} at visit {t}\")\n",
    "#                         feat_vals = np.nan_to_num(feat_vals, nan=0.0, posinf=0.0, neginf=0.0)\n",
    "                    \n",
    "#                     tab_vals = tabs[i, t].cpu().numpy()\n",
    "                    \n",
    "#                     row = {\n",
    "#                         \"PTID\": ptids[i],\n",
    "#                         \"Years_bl\": float(times[i, t].cpu()),\n",
    "#                         \"MMSE\": float(mmse[i, t]),\n",
    "#                         \"time_to_event\": float(t_event[i]),\n",
    "#                         \"event\": int(event[i]),\n",
    "#                     }\n",
    "                    \n",
    "#                     # Add clinical features with proper names\n",
    "#                     tab_feature_names = TEMPORAL_FEATURES + STATIC_FEATURES\n",
    "#                     for f in BASELINE_FEATURES:\n",
    "#                         if f in tab_feature_names:\n",
    "#                             idx = tab_feature_names.index(f)\n",
    "#                             if idx < len(tab_vals):\n",
    "#                                 val = float(tab_vals[idx])\n",
    "#                                 # *** CRITICAL: Check tabular features too ***\n",
    "#                                 if np.isnan(val) or np.isinf(val):\n",
    "#                                     val = 0.0\n",
    "#                                 r_name = f.replace('_encoded', '')\n",
    "#                                 row[r_name] = val\n",
    "                    \n",
    "#                     # Add ADAS13\n",
    "#                     if 'ADAS13' in tab_feature_names:\n",
    "#                         idx = tab_feature_names.index('ADAS13')\n",
    "#                         if idx < len(tab_vals):\n",
    "#                             val = float(tab_vals[idx])\n",
    "#                             if np.isnan(val) or np.isinf(val):\n",
    "#                                 val = 0.0\n",
    "#                             row['ADAS13'] = val\n",
    "                    \n",
    "#                     # Add learned features (call them z_ for consistency)\n",
    "#                     for k in range(len(feat_vals)):\n",
    "#                         row[f\"z_{k}\"] = float(feat_vals[k])\n",
    "                    \n",
    "#                     rows.append(row)\n",
    "    \n",
    "#     df = pd.DataFrame(rows).sort_values(['PTID', 'Years_bl'])\n",
    "    \n",
    "#     # *** FINAL CHECK: Replace any remaining NaN/Inf ***\n",
    "#     numeric_cols = df.select_dtypes(include=[np.number]).columns\n",
    "#     for col in numeric_cols:\n",
    "#         if df[col].isna().any():\n",
    "#             print(f\"WARNING: NaN found in column {col}, filling with 0\")\n",
    "#             df[col].fillna(0, inplace=True)\n",
    "#         if np.isinf(df[col]).any():\n",
    "#             print(f\"WARNING: Inf found in column {col}, replacing with 0\")\n",
    "#             df[col] = df[col].replace([np.inf, -np.inf], 0)\n",
    "    \n",
    "#     df.to_csv(output_path, index=False)\n",
    "    \n",
    "#     print(f\"\\n✓ Exported to {output_path}\")\n",
    "#     print(f\"  Patients: {df['PTID'].nunique()}\")\n",
    "#     print(f\"  Visits: {len(df)}\")\n",
    "#     print(f\"  Features: {len([c for c in df.columns if c.startswith('z_')])}\")\n",
    "#     print(f\"  NaN check: {df.isna().sum().sum()} NaN values\")\n",
    "#     print(f\"  Inf check: {np.isinf(df.select_dtypes(include=[np.number])).sum().sum()} Inf values\")\n",
    "    \n",
    "#     return df\n",
    "\n",
    "# # ============================================================================\n",
    "# # MAIN\n",
    "# # ============================================================================\n",
    "\n",
    "# def main():\n",
    "#     print(\"=\" * 80)\n",
    "#     print(\"BENCHMARK 5: NO AUTOENCODER (Direct Tensor Fusion)\")\n",
    "#     print(\"=\" * 80)\n",
    "    \n",
    "#     device = CONFIG['device']\n",
    "    \n",
    "#     # Load valid patients\n",
    "#     print(\"\\nLoading valid patient list...\")\n",
    "#     with open('VALID_PATIENTS.pkl', 'rb') as f:\n",
    "#         VALID_PATIENTS = pickle.load(f)\n",
    "#     print(f\"Valid patients: {len(VALID_PATIENTS)}\")\n",
    "    \n",
    "#     manifest = pd.read_csv(\"./AD_Multimodal/TFN_AD/AD_Patient_Manifest.csv\")\n",
    "    \n",
    "#     transform = transforms.Compose([\n",
    "#         transforms.Resize((224, 224)),\n",
    "#         transforms.ToTensor(),\n",
    "#         transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "#     ])\n",
    "    \n",
    "#     dataset = SequenceDataset(manifest, VALID_PATIENTS, transform, max_seq_len=CONFIG['max_seq_len'])\n",
    "#     print(f\"Total sequences: {len(dataset)}\")\n",
    "    \n",
    "#     n_train = int(0.8 * len(dataset))\n",
    "#     n_val = len(dataset) - n_train\n",
    "#     train_dataset, val_dataset = torch.utils.data.random_split(\n",
    "#         dataset, [n_train, n_val], generator=torch.Generator().manual_seed(42)\n",
    "#     )\n",
    "    \n",
    "#     train_loader = DataLoader(train_dataset, batch_size=CONFIG['batch_size'], shuffle=True, num_workers=0)\n",
    "#     val_loader = DataLoader(val_dataset, batch_size=CONFIG['batch_size'], shuffle=False, num_workers=0)\n",
    "    \n",
    "#     tab_dim = next(iter(train_loader))[1].shape[2]\n",
    "    \n",
    "#     model = NoAutoencoderModel(tab_dim, CONFIG).to(device)\n",
    "#     optimizer = torch.optim.AdamW(model.parameters(), lr=CONFIG['lr'], weight_decay=CONFIG['weight_decay'])\n",
    "#     scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='max', factor=0.5, patience=5)\n",
    "    \n",
    "#     print(\"\\nTraining...\")\n",
    "#     best_c_index = 0\n",
    "#     patience_counter = 0\n",
    "    \n",
    "#     for epoch in range(CONFIG['epochs']):\n",
    "#         train_loss = train_epoch(model, train_loader, optimizer, device)\n",
    "#         val_c_index = validate(model, val_loader, device)\n",
    "        \n",
    "#         scheduler.step(val_c_index)\n",
    "#         print(f\"Epoch {epoch+1}/{CONFIG['epochs']} - Loss: {train_loss:.4f}, C-index: {val_c_index:.4f}\")\n",
    "        \n",
    "#         if val_c_index > best_c_index:\n",
    "#             best_c_index = val_c_index\n",
    "#             torch.save(model.state_dict(), 'no_autoencoder_model.pth')\n",
    "#             patience_counter = 0\n",
    "#         else:\n",
    "#             patience_counter += 1\n",
    "        \n",
    "#         if patience_counter >= 15:\n",
    "#             break\n",
    "    \n",
    "#     model.load_state_dict(torch.load('no_autoencoder_model.pth'))\n",
    "#     full_loader = DataLoader(dataset, batch_size=CONFIG['batch_size'], shuffle=False, num_workers=0)\n",
    "#     export_features(model, full_loader, device, \"no_autoencoder_features.csv\")\n",
    "    \n",
    "#     print(\"\\n\" + \"=\" * 80)\n",
    "#     print(f\"✓ BEST C-INDEX: {best_c_index:.4f}\")\n",
    "#     print(\"=\" * 80)\n",
    "\n",
    "# if __name__ == \"__main__\":\n",
    "#     main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45cb7c11-de3f-4123-8717-d11a3e2cbdbb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
