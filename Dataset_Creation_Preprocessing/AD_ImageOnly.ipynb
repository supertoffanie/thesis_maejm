{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fab7e807-0a02-4440-b76e-8475ae74c0aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "BENCHMARK 2: IMAGE-ONLY MODEL\n",
      "================================================================================\n",
      "\n",
      "Device: cuda\n",
      "\n",
      "Loading valid patient list...\n",
      "Valid patients to process: 161\n",
      "  Processed: 161 valid patients\n",
      "  Skipped (not in valid set): 221\n",
      "Total sequences: 161\n",
      "\n",
      "Training...\n",
      "Epoch 1/100 - Loss: 2.3631, C-index: 0.4829\n",
      "Epoch 2/100 - Loss: 2.3223, C-index: 0.5265\n",
      "Epoch 3/100 - Loss: 2.1861, C-index: 0.5701\n",
      "Epoch 4/100 - Loss: 1.8151, C-index: 0.5919\n",
      "Epoch 5/100 - Loss: 1.4998, C-index: 0.6231\n",
      "Epoch 6/100 - Loss: 1.5734, C-index: 0.6137\n",
      "Epoch 7/100 - Loss: 1.2856, C-index: 0.4766\n",
      "Epoch 8/100 - Loss: 1.2950, C-index: 0.4798\n",
      "Epoch 9/100 - Loss: 1.2088, C-index: 0.4766\n",
      "Epoch 10/100 - Loss: 1.2103, C-index: 0.5514\n",
      "Epoch 11/100 - Loss: 1.4386, C-index: 0.5607\n",
      "Epoch 12/100 - Loss: 1.1520, C-index: 0.5202\n",
      "Epoch 13/100 - Loss: 1.0775, C-index: 0.5109\n",
      "Epoch 14/100 - Loss: 0.8756, C-index: 0.5826\n",
      "Epoch 15/100 - Loss: 0.9555, C-index: 0.5763\n",
      "Epoch 16/100 - Loss: 1.0185, C-index: 0.5140\n",
      "Epoch 17/100 - Loss: 1.0639, C-index: 0.5327\n",
      "Epoch 18/100 - Loss: 0.8031, C-index: 0.5607\n",
      "Epoch 19/100 - Loss: 0.8000, C-index: 0.5888\n",
      "Epoch 20/100 - Loss: 0.6924, C-index: 0.5732\n",
      "Early stopping\n",
      "\n",
      "✓ Exported to image_only_features.csv\n",
      "  Patients: 161, Features: 256\n",
      "\n",
      "================================================================================\n",
      "✓ BEST C-INDEX: 0.6231\n",
      "================================================================================\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Benchmark 2: Image-Only Model\n",
    "Tests whether MRI scans alone can predict AD conversion\n",
    "\n",
    "Architecture:\n",
    "- ResNet18 image encoder\n",
    "- LSTM for temporal modeling\n",
    "- NO tabular features\n",
    "- Shows need for multimodal integration\n",
    "\"\"\"\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torchvision import models, transforms\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from PIL import Image\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import pickle\n",
    "from lifelines.utils import concordance_index\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "CONFIG = {\n",
    "    'img_out_dim': 256,\n",
    "    'lstm_hidden': 128,\n",
    "    'lstm_layers': 2,\n",
    "    'dropout': 0.3,\n",
    "    'lr': 5e-4,\n",
    "    'weight_decay': 1e-4,\n",
    "    'epochs': 100,\n",
    "    'batch_size': 16,\n",
    "    'max_seq_len': 10,\n",
    "    'device': 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "}\n",
    "\n",
    "# ============================================================================\n",
    "# DATASET\n",
    "# ============================================================================\n",
    "\n",
    "class ImageOnlyDataset(Dataset):\n",
    "    def __init__(self, manifest, valid_patients, transform=None, max_seq_len=10):\n",
    "        self.sequences = []\n",
    "        self.transform = transform\n",
    "        self.max_seq_len = max_seq_len\n",
    "        \n",
    "        manifest[\"path\"] = manifest[\"path\"].str.replace(\"\\\\\", \"/\", regex=False)\n",
    "        manifest[\"path\"] = \"./AD_Multimodal/TFN_AD/\" + manifest[\"path\"]\n",
    "\n",
    "        processed = 0\n",
    "        skipped_not_valid = 0\n",
    "        \n",
    "        for ptid in manifest['PTID'].unique():\n",
    "            if ptid not in valid_patients:\n",
    "                skipped_not_valid += 1\n",
    "                continue\n",
    "                \n",
    "            try:\n",
    "                patient_rows = manifest[manifest['PTID'] == ptid]\n",
    "                if len(patient_rows) == 0:\n",
    "                    continue\n",
    "                \n",
    "                df = pd.read_pickle(patient_rows.iloc[0][\"path\"])\n",
    "                \n",
    "                dx_seq = df[\"DX\"].tolist()\n",
    "                if \"MCI\" not in dx_seq:\n",
    "                    continue\n",
    "                \n",
    "                mci_idx = dx_seq.index(\"MCI\")\n",
    "                ad_idx = next((i for i, x in enumerate(dx_seq[mci_idx+1:], start=mci_idx+1) \n",
    "                              if x in [\"AD\", \"Dementia\"]), -1)\n",
    "                \n",
    "                if ad_idx != -1:\n",
    "                    time_to_event = df[\"Years_bl\"].iloc[ad_idx]\n",
    "                    event = 1\n",
    "                else:\n",
    "                    time_to_event = df[\"Years_bl\"].iloc[-1]\n",
    "                    event = 0\n",
    "                \n",
    "                imgs, times = [], []\n",
    "                valid_visits = 0\n",
    "                \n",
    "                for _, visit in df.iterrows():\n",
    "                    image_path = visit[\"image_path\"].replace(\n",
    "                        \"/home/mason/ADNI_Dataset/\", \n",
    "                        \"./AD_Multimodal/ADNI_Dataset/\"\n",
    "                    )\n",
    "                    \n",
    "                    if not os.path.exists(image_path):\n",
    "                        continue\n",
    "                    \n",
    "                    img = Image.open(image_path).convert(\"RGB\")\n",
    "                    if self.transform:\n",
    "                        img = self.transform(img)\n",
    "                    \n",
    "                    imgs.append(img)\n",
    "                    times.append(visit[\"Years_bl\"])\n",
    "                    valid_visits += 1\n",
    "                    \n",
    "                    if valid_visits >= max_seq_len:\n",
    "                        break\n",
    "                \n",
    "                if valid_visits < 2:\n",
    "                    continue\n",
    "                \n",
    "                pad_len = max_seq_len - len(imgs)\n",
    "                if pad_len > 0:\n",
    "                    for _ in range(pad_len):\n",
    "                        imgs.append(torch.zeros_like(imgs[-1]))\n",
    "                        times.append(times[-1])\n",
    "                \n",
    "                self.sequences.append({\n",
    "                    'ptid': ptid,\n",
    "                    'imgs': torch.stack(imgs),\n",
    "                    'times': np.array(times, dtype=np.float32),\n",
    "                    'seq_len': valid_visits,\n",
    "                    'time_to_event': time_to_event,\n",
    "                    'event': event\n",
    "                })\n",
    "\n",
    "                processed += 1\n",
    "                \n",
    "            except Exception as e:\n",
    "                continue\n",
    "\n",
    "        print(f\"  Processed: {processed} valid patients\")\n",
    "        print(f\"  Skipped (not in valid set): {skipped_not_valid}\")\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.sequences)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        seq = self.sequences[idx]\n",
    "        return (\n",
    "            seq['imgs'], seq['times'], seq['seq_len'],\n",
    "            seq['time_to_event'], seq['event'], seq['ptid']\n",
    "        )\n",
    "\n",
    "# ============================================================================\n",
    "# MODEL\n",
    "# ============================================================================\n",
    "\n",
    "class ImageOnlyModel(nn.Module):\n",
    "    def __init__(self, config):\n",
    "        super().__init__()\n",
    "        self.config = config\n",
    "        \n",
    "        # Image encoder (ResNet18)\n",
    "        base = models.resnet18(pretrained=True)\n",
    "        for param in list(base.parameters())[:-20]:\n",
    "            param.requires_grad = False\n",
    "        \n",
    "        self.features = nn.Sequential(*list(base.children())[:-1])\n",
    "        self.img_proj = nn.Linear(512, config['img_out_dim'])\n",
    "        \n",
    "        # LSTM for temporal modeling\n",
    "        self.lstm = nn.LSTM(\n",
    "            input_size=config['img_out_dim'],\n",
    "            hidden_size=config['lstm_hidden'],\n",
    "            num_layers=config['lstm_layers'],\n",
    "            batch_first=True,\n",
    "            dropout=config['dropout'] if config['lstm_layers'] > 1 else 0,\n",
    "            bidirectional=True\n",
    "        )\n",
    "        \n",
    "        # Risk prediction head\n",
    "        self.risk_head = nn.Sequential(\n",
    "            nn.Linear(config['lstm_hidden'] * 2, 64),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(config['dropout']),\n",
    "            nn.Linear(64, 1)\n",
    "        )\n",
    "    \n",
    "    def encode_image(self, img):\n",
    "        feats = self.features(img)\n",
    "        feats = feats.view(feats.size(0), -1)\n",
    "        return self.img_proj(feats)\n",
    "    \n",
    "    def forward(self, img_seq, seq_lengths):\n",
    "        batch_size, seq_len = img_seq.shape[:2]\n",
    "        \n",
    "        # Encode each image\n",
    "        img_feats = []\n",
    "        for t in range(seq_len):\n",
    "            feat = self.encode_image(img_seq[:, t])\n",
    "            img_feats.append(feat)\n",
    "        \n",
    "        img_seq_feat = torch.stack(img_feats, dim=1)\n",
    "        \n",
    "        # LSTM\n",
    "        packed = nn.utils.rnn.pack_padded_sequence(\n",
    "            img_seq_feat, seq_lengths.cpu(), batch_first=True, enforce_sorted=False\n",
    "        )\n",
    "        lstm_out, (h_n, c_n) = self.lstm(packed)\n",
    "        \n",
    "        h_forward = h_n[-2]\n",
    "        h_backward = h_n[-1]\n",
    "        h_final = torch.cat([h_forward, h_backward], dim=1)\n",
    "        \n",
    "        risk_score = self.risk_head(h_final)\n",
    "        \n",
    "        return risk_score\n",
    "\n",
    "# ============================================================================\n",
    "# LOSS & TRAINING\n",
    "# ============================================================================\n",
    "\n",
    "def cox_loss(risk_scores, times, events):\n",
    "    order = torch.argsort(times, descending=True)\n",
    "    risk_scores = risk_scores[order]\n",
    "    events = events[order]\n",
    "    \n",
    "    log_risk = risk_scores.view(-1)\n",
    "    log_cumsum_hazard = torch.logcumsumexp(log_risk, dim=0)\n",
    "    loss = -(log_risk - log_cumsum_hazard) * events\n",
    "    \n",
    "    return loss.sum() / (events.sum() + 1e-7)\n",
    "\n",
    "def train_epoch(model, loader, optimizer, device):\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    \n",
    "    for batch in loader:\n",
    "        imgs, times, seq_lens, t_event, event, _ = batch\n",
    "        \n",
    "        imgs = imgs.to(device)\n",
    "        seq_lens = torch.LongTensor(seq_lens)\n",
    "        t_event = t_event.float().to(device)\n",
    "        event = event.float().to(device)\n",
    "        \n",
    "        risk_scores = model(imgs, seq_lens)\n",
    "        loss = cox_loss(risk_scores.squeeze(), t_event, event)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
    "        optimizer.step()\n",
    "        \n",
    "        total_loss += loss.item()\n",
    "    \n",
    "    return total_loss / len(loader)\n",
    "\n",
    "def validate(model, loader, device):\n",
    "    model.eval()\n",
    "    all_risks, all_times, all_events = [], [], []\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for batch in loader:\n",
    "            imgs, times, seq_lens, t_event, event, _ = batch\n",
    "            \n",
    "            imgs = imgs.to(device)\n",
    "            seq_lens = torch.LongTensor(seq_lens)\n",
    "            \n",
    "            risk_scores = model(imgs, seq_lens)\n",
    "            \n",
    "            all_risks.extend(risk_scores.cpu().numpy().flatten())\n",
    "            all_times.extend(t_event.numpy())\n",
    "            all_events.extend(event.numpy())\n",
    "    \n",
    "    all_events = np.array(all_events).astype(bool)\n",
    "    all_times = np.array(all_times)\n",
    "    all_risks = np.array(all_risks)\n",
    "    \n",
    "    c_index = concordance_index(all_times, -all_risks, all_events)\n",
    "    return c_index\n",
    "\n",
    "# ============================================================================\n",
    "# EXPORT FOR R\n",
    "# ============================================================================\n",
    "\n",
    "def export_features(model, loader, device, output_path):\n",
    "    \"\"\"Export image features - SURVIVAL DATA ONLY (no longitudinal)\"\"\"\n",
    "    model.eval()\n",
    "    rows = []\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for batch in loader:\n",
    "            imgs, times, seq_lens, t_event, event, ptids = batch\n",
    "            \n",
    "            imgs = imgs.to(device)\n",
    "            seq_lens = torch.LongTensor(seq_lens)\n",
    "            \n",
    "            # Only use FIRST visit for each patient (baseline)\n",
    "            for i in range(len(ptids)):\n",
    "                # Extract features from first visit only\n",
    "                img_feat = model.encode_image(imgs[i:i+1, 0])\n",
    "                \n",
    "                row = {\n",
    "                    \"PTID\": ptids[i],\n",
    "                    \"Years_bl\": float(times[i][0]),\n",
    "                    \"time_to_event\": float(t_event[i]),\n",
    "                    \"event\": int(event[i])\n",
    "                }\n",
    "                \n",
    "                feat_vals = img_feat[0].cpu().numpy()\n",
    "                for k in range(len(feat_vals)):\n",
    "                    row[f\"img_feat_{k}\"] = float(feat_vals[k])\n",
    "                \n",
    "                rows.append(row)\n",
    "    \n",
    "    df = pd.DataFrame(rows).sort_values(['PTID', 'Years_bl'])\n",
    "    df.to_csv(output_path, index=False)\n",
    "    \n",
    "    print(f\"\\n✓ Exported to {output_path}\")\n",
    "    print(f\"  Patients: {df['PTID'].nunique()}, Features: {len([c for c in df.columns if c.startswith('img_feat')])}\")\n",
    "    \n",
    "    return df\n",
    "\n",
    "# ============================================================================\n",
    "# MAIN\n",
    "# ============================================================================\n",
    "\n",
    "def main():\n",
    "    print(\"=\" * 80)\n",
    "    print(\"BENCHMARK 2: IMAGE-ONLY MODEL\")\n",
    "    print(\"=\" * 80)\n",
    "    \n",
    "    device = CONFIG['device']\n",
    "    print(f\"\\nDevice: {device}\")\n",
    "    \n",
    "    manifest = pd.read_csv(\"./AD_Multimodal/TFN_AD/AD_Patient_Manifest.csv\")\n",
    "\n",
    "    # Load valid patients\n",
    "    print(\"\\nLoading valid patient list...\")\n",
    "    with open('VALID_PATIENTS.pkl', 'rb') as f:\n",
    "        VALID_PATIENTS = pickle.load(f)\n",
    "    print(f\"Valid patients to process: {len(VALID_PATIENTS)}\")\n",
    "    \n",
    "    transform = transforms.Compose([\n",
    "        transforms.Resize((224, 224)),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(mean=[0.485, 0.456, 0.406], \n",
    "                           std=[0.229, 0.224, 0.225])\n",
    "    ])\n",
    "    \n",
    "    dataset = ImageOnlyDataset(manifest, VALID_PATIENTS, transform, max_seq_len=CONFIG['max_seq_len'])\n",
    "    print(f\"Total sequences: {len(dataset)}\")\n",
    "    \n",
    "    n_train = int(0.8 * len(dataset))\n",
    "    n_val = len(dataset) - n_train\n",
    "    train_dataset, val_dataset = torch.utils.data.random_split(\n",
    "        dataset, [n_train, n_val], generator=torch.Generator().manual_seed(42)\n",
    "    )\n",
    "    \n",
    "    train_loader = DataLoader(train_dataset, batch_size=CONFIG['batch_size'], \n",
    "                             shuffle=True, num_workers=0)\n",
    "    val_loader = DataLoader(val_dataset, batch_size=CONFIG['batch_size'], \n",
    "                           shuffle=False, num_workers=0)\n",
    "    \n",
    "    model = ImageOnlyModel(CONFIG).to(device)\n",
    "    optimizer = torch.optim.AdamW(model.parameters(), lr=CONFIG['lr'], \n",
    "                                  weight_decay=CONFIG['weight_decay'])\n",
    "    scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(\n",
    "        optimizer, mode='max', factor=0.5, patience=5\n",
    "    )\n",
    "    \n",
    "    print(\"\\nTraining...\")\n",
    "    best_c_index = 0\n",
    "    patience_counter = 0\n",
    "    \n",
    "    for epoch in range(CONFIG['epochs']):\n",
    "        train_loss = train_epoch(model, train_loader, optimizer, device)\n",
    "        val_c_index = validate(model, val_loader, device)\n",
    "        \n",
    "        scheduler.step(val_c_index)\n",
    "        \n",
    "        print(f\"Epoch {epoch+1}/{CONFIG['epochs']} - Loss: {train_loss:.4f}, C-index: {val_c_index:.4f}\")\n",
    "        \n",
    "        if val_c_index > best_c_index:\n",
    "            best_c_index = val_c_index\n",
    "            torch.save(model.state_dict(), 'image_only_model.pth')\n",
    "            patience_counter = 0\n",
    "        else:\n",
    "            patience_counter += 1\n",
    "        \n",
    "        if patience_counter >= 15:\n",
    "            print(\"Early stopping\")\n",
    "            break\n",
    "    \n",
    "    # Export\n",
    "    model.load_state_dict(torch.load('image_only_model.pth'))\n",
    "    full_loader = DataLoader(dataset, batch_size=CONFIG['batch_size'], \n",
    "                            shuffle=False, num_workers=0)\n",
    "    \n",
    "    export_features(model, full_loader, device, \"image_only_features.csv\")\n",
    "    \n",
    "    print(\"\\n\" + \"=\" * 80)\n",
    "    print(f\"✓ BEST C-INDEX: {best_c_index:.4f}\")\n",
    "    print(\"=\" * 80)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0039acbd-599b-4e04-b486-5b73240c54f6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
